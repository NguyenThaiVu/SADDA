{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WQLsH4jSJUvG"
      },
      "outputs": [],
      "source": [
        "# !cp -r \"/content/drive/MyDrive/my_data/Semi_ADDA/data/CALTECH_data.h5\" ./CALTECH_data.h5\n",
        "# !cp -r \"/content/drive/MyDrive/my_data/Semi_ADDA/data/PASCAL_data.h5\" ./PASCAL_data.h5\n",
        "# !cp -r \"/content/drive/MyDrive/my_data/Semi_ADDA/data/LABELME_data.h5\" ./LABELME_data.h5\n",
        "# !cp -r \"/content/drive/MyDrive/my_data/Semi_ADDA/data/SUN_data.h5\" ./SUN_data.h5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGURBwNeApTf"
      },
      "source": [
        "# Source code of SEMI-SUPERVISED ADVERSARIAL DISCRIMINATIVE DOMAIN ADAPTATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SFNVSAbSJlV1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import cv2\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from imutils import build_montages\n",
        "import h5py\n",
        "from functools import reduce\n",
        "import os\n",
        "import scipy.io as sio\n",
        "import urllib.request\n",
        "import shutil\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, \\\n",
        "    Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout, LeakyReLU, GlobalAveragePooling2D, Conv2DTranspose, \\\n",
        "    Reshape, Lambda, ReLU\n",
        "from tensorflow.keras.models import  Model, load_model, Sequential, clone_model\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "from tensorflow.python.keras import regularizers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoXbBuAmEakS"
      },
      "source": [
        "# Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MSRgNoG5EWS1"
      },
      "outputs": [],
      "source": [
        "TRAIN_SOURCE_EPOCHS = 20\n",
        "ADVERSARIAL_EPOCHS = 10\n",
        "BATCH_SIZE = 64\n",
        "NUM_CLASSES = 5\n",
        "\n",
        "IMAGE_SIZE = 64\n",
        "IMAGE_CHANNEL = 3\n",
        "LABEL_NAMES = ['bird', 'car', 'chair', 'dog', 'person']\n",
        "\n",
        "# params for source dataset and target dataset\n",
        "src_dataset = \"labelme\"\n",
        "src_model_trained = True\n",
        "tgt_dataset = \"caltech\"\n",
        "tgt_model_trained = True\n",
        "\n",
        "# params for optimizing models\n",
        "d_learning_rate = 1e-4\n",
        "c_learning_rate = 1e-4\n",
        "BETA1 = 0.5\n",
        "BETA2 = 0.9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4pETCUngvjm"
      },
      "source": [
        "# Get dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "otIQDZlRMKDL"
      },
      "outputs": [],
      "source": [
        "def read_file_data(file_name='/content/CALTECH_data.h5'):\n",
        "\n",
        "    hf = h5py.File(file_name, 'r')\n",
        "    \n",
        "    X_train = hf.get('X_train')\n",
        "    y_train = hf.get('y_train')\n",
        "    X_train = np.array(X_train)\n",
        "    y_train = np.array(y_train)\n",
        "\n",
        "    X_validation = hf.get('X_validation')\n",
        "    y_validation = hf.get('y_validation')\n",
        "    X_validation = np.array(X_validation)\n",
        "    y_validation = np.array(y_validation)\n",
        "\n",
        "    X_test = hf.get('X_test')\n",
        "    y_test = hf.get('y_test')\n",
        "    X_test = np.array(X_test)\n",
        "    y_test = np.array(y_test)\n",
        "\n",
        "    hf.close()\n",
        "    return ((X_train, y_train), (X_validation, y_validation), (X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xJh3lqc_xRf_"
      },
      "outputs": [],
      "source": [
        "def get_dataset(dataset='caltech'):\n",
        "    \n",
        "    if dataset=='caltech':\n",
        "        ((X_train, y_train), (X_validation, y_validation), (X_test, y_test)) = read_file_data(file_name='/content/CALTECH_data.h5')\n",
        "    elif dataset=='labelme':\n",
        "        ((X_train, y_train), (X_validation, y_validation), (X_test, y_test)) = read_file_data(file_name='/content/LABELME_data.h5')\n",
        "    elif dataset=='pascal':\n",
        "        ((X_train, y_train), (X_validation, y_validation), (X_test, y_test)) = read_file_data(file_name='/content/PASCAL_data.h5')\n",
        "    elif dataset=='sun':\n",
        "        ((X_train, y_train), (X_validation, y_validation), (X_test, y_test)) = read_file_data(file_name='/content/SUN_data.h5')\n",
        "    \n",
        "    y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "    y_validation = to_categorical(y_validation, NUM_CLASSES)\n",
        "    y_test = to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "    print(\"---------- INFOR OF DATASET ----------\")\n",
        "    print(\"Name: {}\".format(dataset))\n",
        "    print(\"---- X train shape: {}\".format(X_train.shape))\n",
        "    print(\"---- y train shape: {}\".format(y_train.shape))\n",
        "    print(\"---- X validation shape: {}\".format(X_validation.shape))\n",
        "    print(\"---- y validation shape: {}\".format(y_validation.shape))\n",
        "    print(\"---- X test shape: {}\".format(X_test.shape))\n",
        "    print(\"---- y test shape: {}\".format(y_test.shape))\n",
        "    \n",
        "    return ((X_train, y_train), (X_validation, y_validation), (X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbxztQV6J5wE",
        "outputId": "f3a34846-a8ca-4f90-ea2a-eacc61ec4eaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- INFOR OF DATASET ----------\n",
            "Name: labelme\n",
            "---- X train shape: (20000, 64, 64, 3)\n",
            "---- y train shape: (20000, 5)\n",
            "---- X validation shape: (2500, 64, 64, 3)\n",
            "---- y validation shape: (2500, 5)\n",
            "---- X test shape: (2500, 64, 64, 3)\n",
            "---- y test shape: (2500, 5)\n"
          ]
        }
      ],
      "source": [
        "((X_train, y_train), (X_validation, y_validation), (X_test, y_test)) = get_dataset(src_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "dGsTVH9nGL4T",
        "outputId": "015d4e71-7623-400d-f6a8-d8f20dc58a9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: person\n",
            "Image shape: (64, 64, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa16ef3ed50>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Random plot image\n",
        "idx = np.random.randint(0, X_train.shape[0])\n",
        "test_image = X_train[idx]\n",
        "print(\"Label: {}\".format(LABEL_NAMES[y_train[idx].argmax()]))\n",
        "print(\"Image shape: {}\".format(test_image.shape))\n",
        "\n",
        "plt.imshow(test_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p66Jn2bQrlU_"
      },
      "source": [
        "# Define utils function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "X3jIae7Br8OF"
      },
      "outputs": [],
      "source": [
        "# Nomalize preprocessor \n",
        "class NomalizePreprocessor:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def preprocess(self, image):\n",
        "\n",
        "        # Normalize image in range [0, 1]\n",
        "        image = image.astype(np.float32)\n",
        "        image = (image - 127.5) / 127.5 \n",
        "\n",
        "        # Normalize image in range [0, 1]\n",
        "        # image = image.astype(np.float32) / 255.0\n",
        "\n",
        "        return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qfdNbUcpwfaY"
      },
      "outputs": [],
      "source": [
        "def PredictGenerator(X, batchSize, preprocessors = None):\n",
        "\n",
        "    N = X.shape[0]\n",
        "\n",
        "    for i in np.arange(0, N, batchSize):\n",
        "\n",
        "        images = X[i: i+batchSize]\n",
        "\n",
        "        if preprocessors is not None:\n",
        "            procImages = []\n",
        "\n",
        "            for image in images:\n",
        "                for p in preprocessors:\n",
        "                    image = p.preprocess(image)\n",
        "\n",
        "                procImages.append(image)\n",
        "            \n",
        "            images = np.array(procImages)\n",
        "\n",
        "        yield images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "i2pErhtprnVG"
      },
      "outputs": [],
      "source": [
        "def DatasetGenerator(X, y, batchSize, preprocessors = None, aug = None):\n",
        "\n",
        "    N = X.shape[0]\n",
        "\n",
        "    while True:\n",
        "\n",
        "        # loop over dataset\n",
        "        for i in np.arange(0, N, batchSize):\n",
        "\n",
        "            images = X[i: i+batchSize]\n",
        "            labels = y[i: i+batchSize]\n",
        "\n",
        "            # check to see if our preprocessors are not None\n",
        "            if preprocessors is not None:\n",
        "\n",
        "                # initialize the list of processed images\n",
        "                procImages = []\n",
        "\n",
        "                # loop over the images\n",
        "                for image in images:\n",
        "                    # loop over the preprocessors and apply each to the image\n",
        "                    for p in preprocessors:\n",
        "                        image = p.preprocess(image)\n",
        "\n",
        "                    # update the list of processed images\n",
        "                    procImages.append(image)\n",
        "                \n",
        "                # update the images array to be the processed images\n",
        "                images = np.array(procImages)\n",
        "\n",
        "            if aug is not None: \n",
        "                (images, labels) = next(aug.flow(images, labels, batch_size=batchSize))\n",
        "\n",
        "            # yield a tuple of images and labels\n",
        "            yield (images, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zMcTU6gdphyJ"
      },
      "outputs": [],
      "source": [
        "def Predict_Encoder_Classifier(encoder_model, classifier_model, X, batchSize, preprocessors = None):\n",
        "\n",
        "    predict_labels = np.zeros(shape=(1, NUM_CLASSES))\n",
        "\n",
        "    N = X.shape[0]\n",
        "\n",
        "    for i in np.arange(0, N, batchSize):\n",
        "\n",
        "        images = X[i: i+batchSize]\n",
        "\n",
        "        if preprocessors is not None:\n",
        "            procImages = []\n",
        "\n",
        "            for image in images:\n",
        "                for p in preprocessors:\n",
        "                    image = p.preprocess(image)\n",
        "\n",
        "                procImages.append(image)\n",
        "            \n",
        "            images = np.array(procImages)\n",
        "\n",
        "        predicts = classifier_model(encoder_model(images))\n",
        "\n",
        "        predict_labels = np.concatenate((predict_labels, predicts))\n",
        "    \n",
        "    return predict_labels[1:] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xhMmDavKamr"
      },
      "source": [
        "# Adversarial discriminator domain adaptation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "u3h_OXrR_P-Y"
      },
      "outputs": [],
      "source": [
        "# custom activation function\n",
        "def custom_activation(output):\n",
        "\tlogexpsum = backend.sum(backend.exp(output), axis=-1, keepdims=True)\n",
        "\tresult = logexpsum / (logexpsum + 1.0)\n",
        "\treturn result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4_bYiUyHkaOa"
      },
      "outputs": [],
      "source": [
        "class ADDA():\n",
        "    def __init__(self, source_lr=0.001, disc_lr=0.0002):\n",
        "        \n",
        "        # Input shape \n",
        "        self.img_rows = IMAGE_SIZE\n",
        "        self.img_cols = IMAGE_SIZE\n",
        "        self.channels = IMAGE_CHANNEL\n",
        "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "\n",
        "        self.src_flag = False\n",
        "        self.tgt_flag = False\n",
        "        self.disc_flag = False\n",
        "        self.classifier_flag = False\n",
        "\n",
        "        self.src_optimizer = Adam(source_lr)\n",
        "        self.disc_optimizer = Adam(disc_lr, beta_1=0.5, beta_2=0.9)\n",
        "\n",
        "        self.num_outputs = NUM_CLASSES\n",
        "\n",
        "        self.feature_map = 32\n",
        "\n",
        "    def define_source_encoder(self, weights=None):\n",
        "        \n",
        "        self.source_encoder = Sequential()\n",
        "        self.source_encoder.add(Input(shape=self.img_shape))\n",
        "\n",
        "        self.source_encoder.add(Conv2D(self.feature_map, (4,4), strides=(2,2), padding=\"same\"))\n",
        "        # self.source_encoder.add(BatchNormalization())\n",
        "        self.source_encoder.add(ReLU())\n",
        "\n",
        "        self.source_encoder.add(Conv2D(self.feature_map * 2, (4,4), strides=(2,2), padding=\"same\"))\n",
        "        # self.source_encoder.add(BatchNormalization())\n",
        "        self.source_encoder.add(ReLU())\n",
        "        \n",
        "        self.source_encoder.add(Conv2D(self.feature_map * 4, (4,4), strides=(2,2), padding=\"same\"))\n",
        "        # self.source_encoder.add(BatchNormalization())\n",
        "        self.source_encoder.add(ReLU())\n",
        "\n",
        "        self.source_encoder.add(Conv2D(self.feature_map * 8, (4,4), strides=(2,2), padding=\"same\"))\n",
        "        # self.source_encoder.add(BatchNormalization())\n",
        "        self.source_encoder.add(ReLU())\n",
        "        \n",
        "        self.src_flag = True\n",
        "\n",
        "        if weights is not None:\n",
        "            self.source_encoder.load_weights(weights, by_name=True)\n",
        "    \n",
        "    def define_target_encoder(self, weights=None):\n",
        "        \n",
        "        if not self.src_flag:\n",
        "            self.define_source_encoder()\n",
        "        \n",
        "        with tf.device('/cpu:0'):\n",
        "            self.target_encoder = clone_model(self.source_encoder)\n",
        "            self.tgt_flag = True\n",
        "        \n",
        "        if weights is not None:\n",
        "            self.target_encoder.load_weights(weights, by_name=True)\n",
        "\n",
        "    def define_classifier(self, weights=None):\n",
        "\n",
        "        inputShape = self.source_encoder.output.shape[1:]\n",
        "\n",
        "        self.classifier = Sequential(name=\"Classifier\")\n",
        "        self.classifier.add(Input(shape=inputShape))\n",
        "\n",
        "        self.classifier.add(GlobalAveragePooling2D())\n",
        "        self.classifier.add(Dense(100, activation=\"relu\"))\n",
        "        self.classifier.add(Dropout(0.5))\n",
        "        self.classifier.add(Dense(self.num_outputs, activation=\"softmax\"))\n",
        "\n",
        "        self.classifier_flag = True\n",
        "        self.classifier.summary()\n",
        "\n",
        "        if weights is not None:\n",
        "            self.classifier.load_weights(weights, by_name=True)\n",
        "\n",
        "\n",
        "    def get_encoder_and_classifier(self, weights_classifier=None):\n",
        "        \n",
        "        if not self.classifier_flag:\n",
        "            self.define_classifier(weights_classifier)\n",
        "\n",
        "        input = self.source_encoder.inputs\n",
        "        output = self.classifier(self.source_encoder.outputs)\n",
        "\n",
        "        encoder_classifier_model = Model(inputs=input, outputs=output, name=\"encoder_classifier\")\n",
        "        \n",
        "        return encoder_classifier_model\n",
        "\n",
        "    def define_discriminator(self, encoder_output_shape, hiddens_3 = NUM_CLASSES):\n",
        "\n",
        "        inp = Input(shape=encoder_output_shape)\n",
        "\n",
        "        x = Conv2DTranspose(self.feature_map * 4, (4, 4), strides=(2,2), padding=\"same\")(inp)\n",
        "        # x = BatchNormalization()(x)\n",
        "        x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "        x = Conv2DTranspose(self.feature_map * 2, (4, 4), strides=(2,2), padding=\"same\")(x)\n",
        "        # x = BatchNormalization()(x)\n",
        "        x = LeakyReLU(alpha=0.2)(x)\n",
        "        \n",
        "        x = Conv2DTranspose(self.feature_map, (4, 4), strides=(2,2), padding=\"same\")(x)\n",
        "        # x = BatchNormalization()(x)\n",
        "        x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "        x = Conv2DTranspose(IMAGE_CHANNEL, (4, 4), strides=(2,2), padding=\"same\")(x)\n",
        "        # x = BatchNormalization()(x)\n",
        "        x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "        x = Flatten()(x)\n",
        "\n",
        "        x = Dense(hiddens_3, name='discriminator3')(x)\n",
        "\n",
        "        # Define unsupervised discriminator model\n",
        "        d_out_layer = Lambda(custom_activation)(x)\n",
        "        self.discriminator_model = Model(inputs=(inp), outputs=(d_out_layer), name='unsupervised_discriminator')\n",
        "\n",
        "        # Define supervised discriminator\n",
        "        c_out_layer = Activation(\"softmax\")(x)\n",
        "        self.supervised_discriminator_model = Model(inputs=(inp), outputs=(c_out_layer), name=\"supervised_discriminator\")\n",
        "\n",
        "        self.disc_flag = True\n",
        "\n",
        "\n",
        "    def get_whole_encoder_and_discriminator(self, encoder, weights=None):\n",
        "        \n",
        "        if not self.disc_flag:\n",
        "            self.define_discriminator(encoder.output_shape[1:])\n",
        "        \n",
        "        disc = Model(inputs=(encoder.input), outputs=(self.discriminator_model(encoder.output)))\n",
        "        \n",
        "        if weights is not None:\n",
        "            disc.load_weights(weights, by_name=True)\n",
        "        \n",
        "        return disc\n",
        "\n",
        "    def train_source_model(self, model, epochs=TRAIN_SOURCE_EPOCHS, batch_size=BATCH_SIZE, save_interval=1):\n",
        "\n",
        "        if not os.path.isdir('model'):\n",
        "            os.mkdir('model')\n",
        "\n",
        "        ((X_train, y_train), (X_validation, y_validation), (X_test, y_test)) = get_dataset(src_dataset)\n",
        "\n",
        "        # Preprocess\n",
        "        normPro = NomalizePreprocessor()\n",
        "\n",
        "        # Dataset generator\n",
        "        trainGen = DatasetGenerator(X_train, y_train, batchSize=batch_size, preprocessors = [normPro])\n",
        "        valGen = DatasetGenerator(X_validation, y_validation, batchSize=batch_size, preprocessors = [normPro])\n",
        "\n",
        "        # Early stopping\n",
        "        earlyStoppingCallback = EarlyStopping(monitor='val_accuracy', mode='auto', min_delta=0, patience=5, restore_best_weights=True)\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=self.src_optimizer, metrics=['accuracy'])\n",
        "        model.summary()\n",
        "\n",
        "        N_train = X_train.shape[0]\n",
        "        N_val = X_validation.shape[0]\n",
        "\n",
        "        STEPS_PER_EPOCH = N_train//batch_size\n",
        "        VAL_STEPS = N_val//batch_size\n",
        "\n",
        "        model.fit(trainGen, \\\n",
        "                steps_per_epoch = STEPS_PER_EPOCH, \\\n",
        "                validation_data = valGen, \\\n",
        "                validation_steps = VAL_STEPS, \\\n",
        "                epochs = epochs, \\\n",
        "                callbacks=[earlyStoppingCallback], verbose=1)\n",
        "        \n",
        "        # Evaluate on testing dataset\n",
        "        testGen = PredictGenerator(X_test, batchSize=BATCH_SIZE, preprocessors = [normPro])\n",
        "        y_test_predict = model.predict(testGen)\n",
        "\n",
        "        print('---CLASSIFICATION REPORT ---')\n",
        "        print(classification_report(y_true=y_test.argmax(axis=1), y_pred=y_test_predict.argmax(axis=1)))\n",
        "    \n",
        "        # Save classification model\n",
        "        model.save(os.path.join(\"model\", \"source_classification.h5\"))\n",
        "        \n",
        "        # Save source encoder model \n",
        "        source_encoder = Sequential()\n",
        "        source_encoder.build(self.img_shape)\n",
        "\n",
        "        for layer in model.layers[:-1]:\n",
        "            source_encoder.add(layer)\n",
        "\n",
        "        source_encoder.save(os.path.join(\"model\", \"source_encoder.h5\"))\n",
        "\n",
        "        # Save classifier model\n",
        "        classifier_model = Sequential()\n",
        "        classifier_model.add(Input(source_encoder.output_shape[1:]))\n",
        "\n",
        "        for layer in model.layers[-1:]:\n",
        "            classifier_model.add(layer)\n",
        "\n",
        "        classifier_model.save(os.path.join(\"model\", \"classifier.h5\"))\n",
        "\n",
        "    # ====================================================================================\n",
        "\n",
        "    def train_target(self, epochs=ADVERSARIAL_EPOCHS, batch_size=BATCH_SIZE, save_interval=1,\n",
        "                    test_images=None, test_labels=None):\n",
        "\n",
        "        # 1. Load dataset and define preprocessing method\n",
        "        ((X_train_source, y_train_source), (X_validation_source, y_validation_source), (_, _)) = get_dataset(src_dataset)\n",
        "        source_image = np.concatenate([X_train_source, X_validation_source])\n",
        "        source_label = np.concatenate([y_train_source, y_validation_source])\n",
        "\n",
        "        ((X_train_target, y_train_target), (X_validation_target, y_validation_target), (_, _)) = get_dataset(tgt_dataset)\n",
        "        target_image = np.concatenate([X_train_target, X_validation_target])\n",
        "\n",
        "        normPro = NomalizePreprocessor()\n",
        "\n",
        "        # 2. Define target encoder (if it doesn't exits)\n",
        "        if not self.tgt_flag:\n",
        "            weights = os.path.join(\"model\", \"source_encoder.h5\")\n",
        "            if os.path.isfile(weights):\n",
        "                print(\"[INFO]: target_encoder is copy from {}\".format(weights))\n",
        "                self.define_target_encoder(weights)\n",
        "            else:\n",
        "                self.define_target_encoder()\n",
        "        \n",
        "        # 3. Compile supervised discriminator model and unsupervised discriminator model\n",
        "        self.supervised_discriminator_model.compile(loss='categorical_crossentropy', optimizer=self.disc_optimizer, metrics=['accuracy'])\n",
        "        self.supervised_discriminator_model.summary()\n",
        "\n",
        "        self.discriminator_model.compile(loss=\"binary_crossentropy\", optimizer=self.disc_optimizer)\n",
        "        self.discriminator_model.summary()\n",
        "\n",
        "        # Build adversarial model by setting the discriminator to *not* be trainable\n",
        "        self.discriminator_model.trainable = False\n",
        "\n",
        "        whole_target_disc_model = self.get_whole_encoder_and_discriminator(self.target_encoder)\n",
        "        whole_target_disc_model.compile(loss=\"binary_crossentropy\", optimizer=self.disc_optimizer)\n",
        "        whole_target_disc_model.summary()\n",
        "\n",
        "        # 4. Loop through epoch\n",
        "        for epoch in range(0, epochs):\n",
        "            \n",
        "            print(\"-----[INFO] starting epoch {} of {}...\".format(epoch, epochs))     \n",
        "\n",
        "            # Calculate accuracy (for testing purpose)\n",
        "            if epoch % 3 == 0:\n",
        "\n",
        "                # Checkpoint target_encoder\n",
        "                file_name = \"target_encode_{}.h5\".format(epoch)\n",
        "                self.target_encoder.save(os.path.join(\"model\", file_name))\n",
        "\n",
        "                # Load classifier model\n",
        "                classifier_model = load_model(\"/content/model/classifier.h5\")\n",
        "                \n",
        "                # Predict\n",
        "                normPro = NomalizePreprocessor()\n",
        "                predict_labels = Predict_Encoder_Classifier(self.target_encoder, classifier_model, test_images, batchSize=batch_size, preprocessors=[normPro])\n",
        "\n",
        "                # Calculate accuracy\n",
        "                accuracy = np.sum(predict_labels.argmax(-1) == test_labels.argmax(-1)) / len(test_labels)\n",
        "                print(\" * Accuracy at epoch {}: is {}\".format(epoch, accuracy))       \n",
        "            \n",
        "            # Update learning rate of discriminator \n",
        "            if (epoch > 0) and (epoch % 10 == 0):\n",
        "                new_learning_rate = self.disc_optimizer.learning_rate / 10.0\n",
        "                print(\" * Update learning rate of discriminator model to: \", new_learning_rate)\n",
        "                print(\" * Update learning rate of the whole model to: \", new_learning_rate)\n",
        "                backend.set_value(self.discriminator_model.optimizer.learning_rate, new_learning_rate)\n",
        "                backend.set_value(self.supervised_discriminator_model.optimizer.learning_rate, new_learning_rate)\n",
        "            \n",
        "            N = max([source_image.shape[0], target_image.shape[0]])\n",
        "            n_steps = N // batch_size\n",
        "            for i in np.arange(n_steps):\n",
        "\n",
        "                idx_source = np.random.randint(0, source_image.shape[0], batch_size)\n",
        "                batch_source_image = source_image[idx_source]\n",
        "                batch_source_label = source_label[idx_source]\n",
        "\n",
        "                idx_target = np.random.randint(0, target_image.shape[0], batch_size)\n",
        "                batch_target_image = target_image[idx_target]\n",
        "\n",
        "                # ----- Preprocess image -----\n",
        "                processed_batch_source_image = []\n",
        "                for image in batch_source_image:\n",
        "                    image = normPro.preprocess(image)\n",
        "                    processed_batch_source_image.append(image)\n",
        "                batch_source_image = np.array(processed_batch_source_image)\n",
        "\n",
        "                processed_batch_target_image = []\n",
        "                for image in batch_target_image:\n",
        "                    image = normPro.preprocess(image)\n",
        "                    processed_batch_target_image.append(image)\n",
        "                    \n",
        "                batch_target_image = np.array(processed_batch_target_image)\n",
        "\n",
        "                # ----- Prepare data -----\n",
        "                source_encode = self.source_encoder.predict(batch_source_image)\n",
        "                target_encode = self.target_encoder.predict(batch_target_image)\n",
        "                encode = np.concatenate((source_encode, target_encode))\n",
        "                \n",
        "                encode_label = ([0.9] * batch_source_image.shape[0]) + ([0.1] * batch_target_image.shape[0])  # soft label: source: 0.9, target: 0.1\n",
        "                encode_label = np.reshape(encode_label, (-1,))\n",
        "                (encode, encode_label) = shuffle(encode, encode_label)\n",
        "\n",
        "                # ----- Train supervised discriminator -----\n",
        "                classificationLloss = self.supervised_discriminator_model.train_on_batch(source_encode, batch_source_label)\n",
        "\n",
        "                # ----- Train unsupervised discriminator -----\n",
        "                discLoss = self.discriminator_model.train_on_batch(encode, encode_label)\n",
        "\n",
        "                # ----- Train target encoder -----\n",
        "                fakeLabels = [1.0] * batch_target_image.shape[0]\n",
        "                fakeLabels = np.reshape(fakeLabels, (-1,))\n",
        "                (batch_target_image, fakeLabels) = shuffle(batch_target_image, fakeLabels)\n",
        "\n",
        "                # ----- Adversarial training with interted label -----\n",
        "                adversarialLoss = whole_target_disc_model.train_on_batch(batch_target_image, fakeLabels)\n",
        "\n",
        "            print(\"Classification loss: {}, discriminator loss: {}, adversarial loss: {}\".format(classificationLloss, discLoss, adversarialLoss))\n",
        "\n",
        "        self.target_encoder.save(os.path.join(\"model\", \"target_encoder.h5\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et3bHPGouyW_"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td3zQAXum_Ll",
        "outputId": "bf810ace-3b35-4aeb-e077-27ca2bd47e0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Classifier\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " global_average_pooling2d (G  (None, 256)              0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               25700     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 505       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,205\n",
            "Trainable params: 26,205\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- INFOR OF DATASET ----------\n",
            "Name: labelme\n",
            "---- X train shape: (20000, 64, 64, 3)\n",
            "---- y train shape: (20000, 5)\n",
            "---- X validation shape: (2500, 64, 64, 3)\n",
            "---- y validation shape: (2500, 5)\n",
            "---- X test shape: (2500, 64, 64, 3)\n",
            "---- y test shape: (2500, 5)\n",
            "Model: \"encoder_classifier\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        1568      \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 64)        32832     \n",
            "                                                                 \n",
            " re_lu_1 (ReLU)              (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 128)         131200    \n",
            "                                                                 \n",
            " re_lu_2 (ReLU)              (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 256)         524544    \n",
            "                                                                 \n",
            " re_lu_3 (ReLU)              (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " Classifier (Sequential)     (None, 5)                 26205     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 716,349\n",
            "Trainable params: 716,349\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "312/312 [==============================] - 7s 12ms/step - loss: 1.4435 - accuracy: 0.3432 - val_loss: 1.2721 - val_accuracy: 0.4555\n",
            "Epoch 2/20\n",
            "312/312 [==============================] - 3s 10ms/step - loss: 1.1131 - accuracy: 0.5308 - val_loss: 0.8518 - val_accuracy: 0.6522\n",
            "Epoch 3/20\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.7471 - accuracy: 0.7075 - val_loss: 0.5516 - val_accuracy: 0.7716\n",
            "Epoch 4/20\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.5334 - accuracy: 0.7875 - val_loss: 0.5233 - val_accuracy: 0.7885\n",
            "Epoch 5/20\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.4116 - accuracy: 0.8335 - val_loss: 0.5489 - val_accuracy: 0.7897\n",
            "Epoch 6/20\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.3411 - accuracy: 0.8601 - val_loss: 0.4633 - val_accuracy: 0.8241\n",
            "Epoch 7/20\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.2830 - accuracy: 0.8844 - val_loss: 0.5142 - val_accuracy: 0.8097\n",
            "Epoch 8/20\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.2295 - accuracy: 0.9084 - val_loss: 0.4936 - val_accuracy: 0.8337\n",
            "Epoch 9/20\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.1898 - accuracy: 0.9297 - val_loss: 0.4711 - val_accuracy: 0.8554\n",
            "Epoch 10/20\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.1470 - accuracy: 0.9450 - val_loss: 0.5086 - val_accuracy: 0.8534\n",
            "Epoch 11/20\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.1069 - accuracy: 0.9610 - val_loss: 0.5075 - val_accuracy: 0.8730\n",
            "Epoch 12/20\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.0956 - accuracy: 0.9658 - val_loss: 0.6699 - val_accuracy: 0.8570\n",
            "Epoch 13/20\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.0848 - accuracy: 0.9699 - val_loss: 0.6735 - val_accuracy: 0.8578\n",
            "Epoch 14/20\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.0714 - accuracy: 0.9766 - val_loss: 0.4854 - val_accuracy: 0.8794\n",
            "Epoch 15/20\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.0615 - accuracy: 0.9802 - val_loss: 0.5805 - val_accuracy: 0.8670\n",
            "Epoch 16/20\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.0466 - accuracy: 0.9857 - val_loss: 0.5153 - val_accuracy: 0.8842\n",
            "Epoch 17/20\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.0451 - accuracy: 0.9867 - val_loss: 0.4797 - val_accuracy: 0.8774\n",
            "Epoch 18/20\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.0467 - accuracy: 0.9849 - val_loss: 0.5153 - val_accuracy: 0.8762\n",
            "Epoch 19/20\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.0307 - accuracy: 0.9905 - val_loss: 0.6509 - val_accuracy: 0.8794\n",
            "Epoch 20/20\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.0350 - accuracy: 0.9890 - val_loss: 0.5324 - val_accuracy: 0.8842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---CLASSIFICATION REPORT ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.95      0.96       497\n",
            "           1       0.81      0.83      0.82       525\n",
            "           2       0.90      0.95      0.93       481\n",
            "           3       0.96      0.94      0.95       507\n",
            "           4       0.79      0.76      0.77       490\n",
            "\n",
            "    accuracy                           0.89      2500\n",
            "   macro avg       0.89      0.89      0.89      2500\n",
            "weighted avg       0.89      0.89      0.89      2500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Training base model\n",
        "\n",
        "adda = ADDA()\n",
        "\n",
        "adda.define_source_encoder()\n",
        "\n",
        "adda.define_classifier()\n",
        "\n",
        "model = adda.get_encoder_and_classifier()\n",
        "\n",
        "adda.train_source_model(model, epochs=TRAIN_SOURCE_EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIfxIX8bmETk",
        "outputId": "513fe078-ed36-41ab-cb48-95b5706a7ea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- INFOR OF DATASET ----------\n",
            "Name: caltech\n",
            "---- X train shape: (20000, 64, 64, 3)\n",
            "---- y train shape: (20000, 5)\n",
            "---- X validation shape: (2500, 64, 64, 3)\n",
            "---- y validation shape: (2500, 5)\n",
            "---- X test shape: (2500, 64, 64, 3)\n",
            "---- y test shape: (2500, 5)\n"
          ]
        }
      ],
      "source": [
        "# Load target dataset\n",
        "\n",
        "((X_train_target, y_train_target), (X_validation_target, y_validation_target), (_, _)) = get_dataset(tgt_dataset)\n",
        "\n",
        "target_x = np.concatenate((X_train_target, X_validation_target), axis=0)\n",
        "target_y = np.concatenate((y_train_target, y_validation_target), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpCvG-3I05V_",
        "outputId": "1a30d1f7-a18a-491d-cf13-703674f3d3e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is 0.3075111111111111\n"
          ]
        }
      ],
      "source": [
        "model = load_model(\"/content/model/source_classification.h5\")\n",
        "\n",
        "# Preprocess\n",
        "normPro = NomalizePreprocessor()\n",
        "\n",
        "# Predict\n",
        "testGen = PredictGenerator(target_x, batchSize=BATCH_SIZE, preprocessors = [normPro])\n",
        "\n",
        "predict_labels = model.predict(testGen)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = np.sum(predict_labels.argmax(-1) == target_y.argmax(-1)) / len(target_y)\n",
        "\n",
        "print(\"Accuracy is {}\".format(accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8lfKNCy3ItW",
        "outputId": "e5965a42-1fd0-41f0-bcd4-89279d6a96f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- INFOR OF DATASET ----------\n",
            "Name: labelme\n",
            "---- X train shape: (20000, 64, 64, 3)\n",
            "---- y train shape: (20000, 5)\n",
            "---- X validation shape: (2500, 64, 64, 3)\n",
            "---- y validation shape: (2500, 5)\n",
            "---- X test shape: (2500, 64, 64, 3)\n",
            "---- y test shape: (2500, 5)\n",
            "---------- INFOR OF DATASET ----------\n",
            "Name: caltech\n",
            "---- X train shape: (20000, 64, 64, 3)\n",
            "---- y train shape: (20000, 5)\n",
            "---- X validation shape: (2500, 64, 64, 3)\n",
            "---- y validation shape: (2500, 5)\n",
            "---- X test shape: (2500, 64, 64, 3)\n",
            "---- y test shape: (2500, 5)\n",
            "[INFO]: target_encoder is copy from model/source_encoder.h5\n",
            "Model: \"supervised_discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 4, 4, 256)]       0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 8, 8, 128)        524416    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 16, 16, 64)       131136    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 32, 32, 32)       32800     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 64, 64, 3)        1539      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 64, 64, 3)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12288)             0         \n",
            "                                                                 \n",
            " discriminator3 (Dense)      (None, 5)                 61445     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 751,336\n",
            "Trainable params: 751,336\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"unsupervised_discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 4, 4, 256)]       0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 8, 8, 128)        524416    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 16, 16, 64)       131136    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 32, 32, 32)       32800     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 64, 64, 3)        1539      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 64, 64, 3)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12288)             0         \n",
            "                                                                 \n",
            " discriminator3 (Dense)      (None, 5)                 61445     \n",
            "                                                                 \n",
            " lambda (Lambda)             (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 751,336\n",
            "Trainable params: 751,336\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        1568      \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 64)        32832     \n",
            "                                                                 \n",
            " re_lu_1 (ReLU)              (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 128)         131200    \n",
            "                                                                 \n",
            " re_lu_2 (ReLU)              (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 256)         524544    \n",
            "                                                                 \n",
            " re_lu_3 (ReLU)              (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " unsupervised_discriminator   (None, 1)                751336    \n",
            " (Functional)                                                    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,441,480\n",
            "Trainable params: 690,144\n",
            "Non-trainable params: 751,336\n",
            "_________________________________________________________________\n",
            "-----[INFO] starting epoch 0 of 10..."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Accuracy at epoch 0: is 0.3075111111111111\n",
            "Classification loss: [0.06704945117235184, 0.984375], discriminator loss: 0.5376543402671814, adversarial loss: 1.3963303565979004\n",
            "-----[INFO] starting epoch 1 of 10...\n",
            "Classification loss: [0.023538168519735336, 1.0], discriminator loss: 0.4741498827934265, adversarial loss: 1.718735694885254\n",
            "-----[INFO] starting epoch 2 of 10...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification loss: [0.013603768311440945, 1.0], discriminator loss: 0.43645545840263367, adversarial loss: 1.8512543439865112\n",
            "-----[INFO] starting epoch 3 of 10...\n",
            " * Accuracy at epoch 3: is 0.4108888888888889\n",
            "Classification loss: [0.010048089548945427, 1.0], discriminator loss: 0.4113600254058838, adversarial loss: 1.9876322746276855\n",
            "-----[INFO] starting epoch 4 of 10...\n",
            "Classification loss: [0.011991839855909348, 1.0], discriminator loss: 0.4015122056007385, adversarial loss: 1.8724020719528198\n",
            "-----[INFO] starting epoch 5 of 10...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification loss: [0.0029399851337075233, 1.0], discriminator loss: 0.3945220708847046, adversarial loss: 2.023822546005249\n",
            "-----[INFO] starting epoch 6 of 10...\n",
            " * Accuracy at epoch 6: is 0.4396888888888889\n",
            "Classification loss: [0.007494518533349037, 1.0], discriminator loss: 0.37990039587020874, adversarial loss: 2.0476129055023193\n",
            "-----[INFO] starting epoch 7 of 10...\n",
            "Classification loss: [0.006406066473573446, 1.0], discriminator loss: 0.3726308047771454, adversarial loss: 2.2345376014709473\n",
            "-----[INFO] starting epoch 8 of 10...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification loss: [0.00804173480719328, 1.0], discriminator loss: 0.3723490536212921, adversarial loss: 2.1312098503112793\n",
            "-----[INFO] starting epoch 9 of 10...\n",
            " * Accuracy at epoch 9: is 0.43977777777777777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification loss: [0.0017888182774186134, 1.0], discriminator loss: 0.3771790862083435, adversarial loss: 2.5326528549194336\n"
          ]
        }
      ],
      "source": [
        "# Training adversarial network\n",
        "\n",
        "adda.define_discriminator(adda.source_encoder.output_shape[1:])\n",
        "adda.train_target(epochs=ADVERSARIAL_EPOCHS, test_images=target_x, test_labels=target_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-d-dHOkX0Rjq"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict on the train and validation dataset"
      ],
      "metadata": {
        "id": "Qe0zQY5cHmSG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLYMThc9p6qJ",
        "outputId": "226c4ad2-dab0-4aef-e991-eb62800e3d3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is 0.42995555555555554\n"
          ]
        }
      ],
      "source": [
        "# Predict on the train and validation dataset\n",
        "\n",
        "encoder_model = load_model(\"/content/model/target_encoder.h5\")\n",
        "\n",
        "classifier_model = load_model(\"/content/model/classifier.h5\")\n",
        "\n",
        "predict_labels = Predict_Encoder_Classifier(encoder_model, classifier_model, target_x, batchSize=BATCH_SIZE, preprocessors = [normPro])\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = np.sum(predict_labels.argmax(-1) == target_y.argmax(-1)) / len(target_y)\n",
        "\n",
        "print(\"Accuracy is {}\".format(accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predit on the testing dataset"
      ],
      "metadata": {
        "id": "HicdPzO9TYgG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJlPEiTG8jrr",
        "outputId": "ddfc8b12-c262-4336-c69a-dc105d51cb4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- INFOR OF DATASET ----------\n",
            "Name: caltech\n",
            "---- X train shape: (20000, 64, 64, 3)\n",
            "---- y train shape: (20000, 5)\n",
            "---- X validation shape: (2500, 64, 64, 3)\n",
            "---- y validation shape: (2500, 5)\n",
            "---- X test shape: (2500, 64, 64, 3)\n",
            "---- y test shape: (2500, 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is 0.4296\n"
          ]
        }
      ],
      "source": [
        "# Load target dataset\n",
        "((_, _), (_, _), (X_testing_target, y_testing_target)) = get_dataset(tgt_dataset)\n",
        "\n",
        "# Predict\n",
        "encoder_model = load_model(\"/content/model/target_encoder.h5\")\n",
        "classifier_model = load_model(\"/content/model/classifier.h5\")\n",
        "\n",
        "predict_labels = Predict_Encoder_Classifier(encoder_model, classifier_model, X_testing_target, batchSize=BATCH_SIZE, preprocessors = [normPro])\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = np.sum(predict_labels.argmax(-1) == y_testing_target.argmax(-1)) / len(y_testing_target)\n",
        "print(\"Accuracy is {}\".format(accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sPflYB1kUKPf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}