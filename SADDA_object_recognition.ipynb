{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WQLsH4jSJUvG"
      },
      "outputs": [],
      "source": [
        "# !cp -r \"/content/drive/MyDrive/my_data/Semi_ADDA/data/CALTECH_data.h5\" ./CALTECH_data.h5\n",
        "# !cp -r \"/content/drive/MyDrive/my_data/Semi_ADDA/data/PASCAL_data.h5\" ./PASCAL_data.h5\n",
        "# !cp -r \"/content/drive/MyDrive/my_data/Semi_ADDA/data/LABELME_data.h5\" ./LABELME_data.h5\n",
        "# !cp -r \"/content/drive/MyDrive/my_data/Semi_ADDA/data/SUN_data.h5\" ./SUN_data.h5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGURBwNeApTf"
      },
      "source": [
        "# Source code of SEMI-SUPERVISED ADVERSARIAL DISCRIMINATIVE DOMAIN ADAPTATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SFNVSAbSJlV1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import cv2\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from imutils import build_montages\n",
        "import h5py\n",
        "from functools import reduce\n",
        "import os\n",
        "import scipy.io as sio\n",
        "import urllib.request\n",
        "import shutil\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, \\\n",
        "    Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout, LeakyReLU, GlobalAveragePooling2D, Conv2DTranspose, \\\n",
        "    Reshape, Lambda, ReLU\n",
        "from tensorflow.keras.models import  Model, load_model, Sequential, clone_model\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "from tensorflow.python.keras import regularizers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoXbBuAmEakS"
      },
      "source": [
        "# Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MSRgNoG5EWS1"
      },
      "outputs": [],
      "source": [
        "TRAIN_SOURCE_EPOCHS = 30\n",
        "ADVERSARIAL_EPOCHS = 20\n",
        "BATCH_SIZE = 64\n",
        "NUM_CLASSES = 5\n",
        "\n",
        "IMAGE_SIZE = 64\n",
        "IMAGE_CHANNEL = 3\n",
        "LABEL_NAMES = ['bird', 'car', 'chair', 'dog', 'person']\n",
        "\n",
        "# params for source dataset and target dataset\n",
        "src_dataset = \"labelme\"\n",
        "src_model_trained = True\n",
        "tgt_dataset = \"caltech\"\n",
        "tgt_model_trained = True\n",
        "\n",
        "# params for optimizing models\n",
        "d_learning_rate = 1e-4\n",
        "c_learning_rate = 1e-4\n",
        "BETA1 = 0.5\n",
        "BETA2 = 0.9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4pETCUngvjm"
      },
      "source": [
        "# Get dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "otIQDZlRMKDL"
      },
      "outputs": [],
      "source": [
        "def read_file_data(file_name='/content/CALTECH_data.h5'):\n",
        "\n",
        "    hf = h5py.File(file_name, 'r')\n",
        "    \n",
        "    X_train = hf.get('X_train')\n",
        "    y_train = hf.get('y_train')\n",
        "    X_train = np.array(X_train)\n",
        "    y_train = np.array(y_train)\n",
        "\n",
        "    X_validation = hf.get('X_validation')\n",
        "    y_validation = hf.get('y_validation')\n",
        "    X_validation = np.array(X_validation)\n",
        "    y_validation = np.array(y_validation)\n",
        "\n",
        "    X_test = hf.get('X_test')\n",
        "    y_test = hf.get('y_test')\n",
        "    X_test = np.array(X_test)\n",
        "    y_test = np.array(y_test)\n",
        "\n",
        "    hf.close()\n",
        "    return ((X_train, y_train), (X_validation, y_validation), (X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xJh3lqc_xRf_"
      },
      "outputs": [],
      "source": [
        "def get_dataset(dataset='caltech'):\n",
        "    \n",
        "    if dataset=='caltech':\n",
        "        ((X_train, y_train), (X_validation, y_validation), (X_test, y_test)) = read_file_data(file_name='/content/CALTECH_data.h5')\n",
        "    elif dataset=='labelme':\n",
        "        ((X_train, y_train), (X_validation, y_validation), (X_test, y_test)) = read_file_data(file_name='/content/LABELME_data.h5')\n",
        "    elif dataset=='pascal':\n",
        "        ((X_train, y_train), (X_validation, y_validation), (X_test, y_test)) = read_file_data(file_name='/content/PASCAL_data.h5')\n",
        "    elif dataset=='sun':\n",
        "        ((X_train, y_train), (X_validation, y_validation), (X_test, y_test)) = read_file_data(file_name='/content/SUN_data.h5')\n",
        "    \n",
        "    y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "    y_validation = to_categorical(y_validation, NUM_CLASSES)\n",
        "    y_test = to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "    print(\"---------- INFOR OF DATASET ----------\")\n",
        "    print(\"Name: {}\".format(dataset))\n",
        "    print(\"---- X train shape: {}\".format(X_train.shape))\n",
        "    print(\"---- y train shape: {}\".format(y_train.shape))\n",
        "    print(\"---- X validation shape: {}\".format(X_validation.shape))\n",
        "    print(\"---- y validation shape: {}\".format(y_validation.shape))\n",
        "    print(\"---- X test shape: {}\".format(X_test.shape))\n",
        "    print(\"---- y test shape: {}\".format(y_test.shape))\n",
        "    \n",
        "    return ((X_train, y_train), (X_validation, y_validation), (X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbxztQV6J5wE",
        "outputId": "a6c6d36b-ccd2-4150-ff1a-08ff166e9c5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- INFOR OF DATASET ----------\n",
            "Name: labelme\n",
            "---- X train shape: (20000, 64, 64, 3)\n",
            "---- y train shape: (20000, 5)\n",
            "---- X validation shape: (2500, 64, 64, 3)\n",
            "---- y validation shape: (2500, 5)\n",
            "---- X test shape: (2500, 64, 64, 3)\n",
            "---- y test shape: (2500, 5)\n"
          ]
        }
      ],
      "source": [
        "((X_train, y_train), (X_validation, y_validation), (X_test, y_test)) = get_dataset(src_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "dGsTVH9nGL4T",
        "outputId": "7c89377f-4004-4224-f579-9a9d611dac7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: car\n",
            "Image shape: (64, 64, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f53e6183690>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO19a6wkx3Xed7pn5j733n0vl7t8ihRXjGwtFUYiTUWmXjYlC2YcWIIlwWACAvzjBDLiwJISILCNBJCAwI8fgQEicswfjiX5SUKWJdEr0RIVmeRSfL+Xy11yl/vm3r17H/Psyo+ZO3XO6anavq+5tPp8wMWtmaqurq7umj6nzjnfIeccDAbDTz+SjR6AwWAYDmyxGwwlgS12g6EksMVuMJQEttgNhpLAFrvBUBKsarET0R1E9BIRHSKiL67VoAwGw9qDVmpnJ6IUwMsAPgbgGIDHAHzGOff82g3PYDCsFSqrOPZ9AA455w4DABF9DcCdAIKLvTY26cantl2yYyIKftZ1seM4sizrl/kPXP6YWP/FzivGq9qKn1b9Q0vBD2FE+wg3i1UmCRP4+LXFOlHnTdhx/LDILRowrNU7fPHTFe0t90yIKVC9sM9Z5sv6XAQ+H7I2c/7Z5AfmxhuZj6WaxdlzaCzODZzl1Sz2PQDeYJ+PAXh/7IDxqW3415/9QndwmRxPkvjPlYocVqVS7ZdrNV8mSlS7CquT515YWOiX2+12oT40+CLg460mso9arTbwGED+6PAyADg2Zn6cfvhifYR+8DqdjjyXeEhlHxNjY/1ymqbh8bI+0kSet1b188iP4/3p8WZZW9Tx44jCi4VfW6KuP038+RwGL0zdZ6Wmnz//udVqibo2+9xs+nKjLfvnfTQbDVHHj+PPpl7bev5lXXcOHvrzrwTbrPsGHRHdQ0QHiehgc3FuvU9nMBgCWM2b/TiAK9jnvb3vBJxz9wK4FwCmd17pmu3er5OTvzMp+92hTNZ1Wv6Xu8HK+leWvw31r794K6e+zN9AAOAoHXgMAGSsz3abqQWJGkfF91FRbzz+9qY0/NZvsV94/Ysu3mRqjPy6dR3H9PS0Hwdk/2OjXnqan5/vl9VwpYTR0W999kYV8ybf3iOjI34cVJV1I4Olg2azKdrxl/nIiJYYBz8T+vlot9kbui6vZb7tpUItOPFxceFJC9wNNuZESTdjE/66FxcXWefhc+kTtDs0cHwcq3mzPwbgeiK6hohqAH4NwAOr6M9gMKwjVvxmd861ieg/APgOgBTAnzjnnluzkRkMhjXFasR4OOe+BeBbazQWg8GwjljVYl8uHBE6vd1vp2w1ba6TtbRONtj0lrrwjmru3AGbhtb/+LCqFalD8p1kXq5V9Q6zL7fUtcR2wYndDmExULp3Sr5dpy132SnxfSbM0sAtBN3j2D6D0vNm53xdi+0U6510qYvLcXRc3R/HLRx6J73u29XUpkCt6j+32n4eXaaumSm3DiOiLmObJHyvQ1thOuxetCH3FSiySigZrCQnnYhJN9PWBH++kaq/T2nECqOf9Xpvn4EiJltzlzUYSgJb7AZDSTBUMR7gYnhxL7lQnf6lKtpHzDxV1HmD1y0qcxKHViy4c0W1WlW1HVby4nM1ke24xxVV1HXCi9qUcIcYOZLFRS8+a8lPzh0Tg1vaMYebnWRdi5kmk9bgeet90y+lahyLdSa6F/R/a7UXg3VCBcypJIPbXQrieWTPEnfmAeIOMSHTpJ4rfi4930vPVWzs9mY3GEoCW+wGQ0lgi91gKAmGqrMTvF5DFA6I0HqH0IWYrpUE9BZ9TKx/7b4Zc+0MtRsZlTq1CIQh7XLLTIzKxTRJfJ+jLBhF626O6+U6kCf1YxHuvdrllkdhKX0ebrB+2Wrp+QhHeUkde3BAi0aqzttoDda/01Q9tnwPJhywJs6t90t4nzk340gUY7hPZdpjpkmtb3Pzr3iG1bkazEy5nH2FUH8Gg+GnFLbYDYaSYANNbytDzGyWRMxmIROJFueKxrMLM4jy6OJicZ7rgEXf5ebCN643eQhVxDPQ6XO3WN1KWYjSQE3oe8Dp6L6AZ1lbibAc2joVelI6mq+DqTKp8n6rCK9H5nmo+kjFvQ1zBOjnN/Q8tluyDx6hqaM1xXjZ85flIgRHg30sjctMbwaDwRa7wVAWDFeMJ+qLGQWp03ptBweP5HaYmYhYqUiRM+SZpFWBRt1TBuXooFwgECG38z947Bo5iiZ2O8QO+TI0Hx4IExpT9zMfsxZNB58wdi0dzasW8BiLEWrkBhk4ne65wsTzahq+F+I4vfPPdsTJqUCYghyIfH467fB8xKjEOH0aLefZKaAe25vdYCgJbLEbDCWBLXaDoSQYuultCcvROUJEgZ2I/tfRXmHyZPyDrAqYjLqVg01PsQi7WNtMH8eV1BX+DGfCu06cODwm/TnQNEn0HgODMgEmgemvKJ1aeEcqE2YlYOqM7R2QVvRd8INsxsavHx0+H/m5Yd6YzMOwlfOO5EQcinwjcG2aCDRm7l3aB8gic2NvdoOhJLDFbjCUBEMPhFkS33UAx2o963LnKtif5sIramYpeu6ciM/L2mQXEDO1yiM48HXaJU4okYX55cUxag5Sdm/ipjJfVFJlkGxCm0T5mavVCTkudm7Bqa+8x2LEECHEjtH3hYv/ee1wcDBQTkXjATMjo6KOB8K02URSblL5GUIZlUyMNxhKD1vsBkNJYIvdYCgJNsz0FjWfFNSVV5q+WbYL/96t9zjykXmD22n9kn/WOvtYbTBXvI7mE5F/qq6mySF60Bz7mdgTkHztqU4M10NHuzgzN2ati3eywYSWOlJRkJEoV99wfrewTh3LeBvNIMvzyqn3aLPN3WXD7ricpL6VhYlVnCYY6X1clemNiP6EiE4T0bPsu61E9CARvdL7v+VS/RgMho1FETH+TwHcob77IoADzrnrARzofTYYDG9jXFKMd879gIiuVl/fCeD2Xvk+AA8B+EKRE66EN/7SfS2vTjVcdR9rMo74UILQpqCFuhf9koSLo4PJDoC8B50LmKU0F3oqOP9k/y4XmzYYnKMvpbB3XWExmzQfPI9UpIHfA1KdyIvCg1OHAUDCOP94Gqe2ujHxqDc+Xn4u9S6OqBNZb05ifCUr3aDb5Zw70SufBLBrhf0YDIYhYdW78a77ExP8PSGie4joIBEdbC7OrfZ0BoNhhVjpbvwpItrtnDtBRLsBnA41dM7dC+BeANi8+xpnYvzyh7IcLjnHdtL5Xq7muxPpjnQnAa+5TGfe5URumtQtgBhNc1XvUrN3SFyMZ951ioNO8gEy0hJtLWCXpi0X/HyZCnBpsWy4IsuqSv3K5057bQrJXaShkkOMzvA6klc8AOCuXvkuAPevsB+DwTAkFDG9/TmAHwO4gYiOEdHdAL4M4GNE9AqAj/Y+GwyGtzGK7MZ/JlD1kTUei8FgWEcMPeptKcNwllMxuH6mjgvoI0kW8X4rOKZIF4VNYTpaTe4/FBxIpPGKo+8C5cipLgGdhmr5vPQ5sxb73Ih4FIrhpppExH+uaotf4P7mU2r5zy1tNmMmu5xBkZkLXXDAahtEmRgFEQUbV6r0fj7GLPfMZb3TGm+8wVB62GI3GEqC4YvxPRFMBwqIdgVlzCwQsNHrpFAfaYBnfTnjWA4H3SU6Wtlxhbpev76Xg3gAVLitCP6JEWosh2Q/gFSTefBoI3VuYZYj7q2n1ARhXpN1VeaZmDFFQZOKCH463X/fom1ivMFQethiNxhKAlvsBkNJMFSdPUkIY7XuKTvqd0YQELRjQfvcnzCSWledO8ShnijdJ0RyqOtEet5YpFFUv5RYWYLlYlhvnb2oS2/UtTjiQs0Ruy8x01PRcehnIuaqWxupYRD0GPlx8ai98PMnn5DBY4xdvb3ZDYaSwBa7wVASDNf0RglGR7pcZbHsTKgqz6FQ+ifNwxWIkgKAsbExfxwTo1pt6Y3F60hxnYXGkQTSQg0ax0bh7TKOGIqK4JqDToi7BXUhPR+cm7+ahk1eSsMUJxTiuVY1WLtE9Z+JyDzWc0UTcXBTpObC6w0sMoX2ZjcYSgJb7AZDSTBkKmnXz5aZD+BnAQA6wysP/GfSy6hqx8U73QdHxogL6qkWlfiUSFGpzbJvcouBi9BRv13w0yTG691safFYmVWAqwLNjuTT48+SNq5IKmn/Pafx1u20tUlk9mXieUZhLrxEpcldWhe2G28wGGyxGwxlgS12g6EkGKrO7lyGZqsOAGhTOIWP1raF35AwP0gNpd5q9MuaNDB0rlaOZzxgSlHHoeLHXwukOtL9dccc4VNXc1IIOS6Iwf3HIvM0+UbmGIe6IEqU18n3KvQ901FZfnxhnVoTMoSQJJH9mEI9yNTI3T7ZtSnSiHZME2b3nqevSuoN0SyWQkpEswlvPXk1Fb53oD0/seRBZ1FvBkPpYYvdYCgJhhwIk2Jy03S3nDMreLTb2vThh1lh4nMSEFkBxesFoML7YB56GUkTCRejdNZSnhaJc6nV1TBCYhmQVw3EGF3OPat7TEz01wiKuHK+uZqj0z1x5yzJqybfDfyozGnxMUj+FhgfkEbdKovBJSvrIxYAxU1l+n6G7vVyTJ3ctMfLYyNyebYa/nmsKS/CpZsWyp4L2JvdYCgNbLEbDCWBLXaDoSQYsukNaLQ6vROHXQZ1VBP/XBEmL9k/13e0eYPXcV384uKiaMfrdGRRyHzSTqXeHyOs4Nei201wfYupfJ122EyU5NyCB5M0poqck8+3Tq/s2H5HwuZbpyFuNP3eSr0lxyi41sXeSpgYImxQk26g+t7y+WhlYZ06tpfC5yoWEafPLV1dl7G3EgA337lMmu8q/DoVY8pSyuYsso9VJP3TFUT0fSJ6noieI6LP977fSkQPEtErvf9bilyMwWDYGBQR49sAfss5dyOAWwD8BhHdCOCLAA44564HcKD32WAwvE1RJNfbCQAneuWLRPQCgD0A7gRwe6/ZfQAeAvCFWF+Zc2j0xOSWTo/DzDoNFXVEdWb6SOr9ckphcU6buNKASaqppB6iwaJ07jO3SCmTlBCRldgX4yJbYB/5eMfHx0W7lJEaVJQYX4HvJOatJnnbJPpECAAWGl6UdC1FyMDE1loS4VUT49D3jJFGVMZEHR+YIHXQpjE23o6yXsY811bSLn+gL/L7rlW0aP/iWfIfGqpZvcUuTqlUSxbHXHot3iZYMwBEdDWAmwA8AmBX74cAAE4C2LWcvgwGw3BReLET0SSAvwLwm865WV7nuj9VA39SiOgeIjpIRAcb87ODmhgMhiGg0GInoiq6C/3PnHN/3fv6FBHt7tXvBnB60LHOuXudczc7524emZhaizEbDIYV4JI6O3WViK8CeME59/us6gEAdwH4cu///ZfuC6CeLqO9RjOmq1QSnaqWN2TlHGsIa6ZyMXOzETeldCIRVNFIMV7OwtFxy3Gb5OYqbkGZnVsIj1EJVKPMpMn1Rm3O5O6ymminWvVfTI57PTrT7ELiBqgbyi6A66iNhjQncVNnoy3dk0O8Kzmdl5N/JuEoxqI6+7JMaFzfZma/hJahszPwfHFtFX0ntgFyz/7SceHnrYid/TYAvw7gGSJ6svfdf0F3kX+DiO4GcBTApwv0ZTAYNghFduMfRvjn4iNrOxyDwbBeGC7hpPPmGkq0iMzbhb3rpFgc9gqLEU5yDE7e0+tPfU4CP3k64Isi/PUxdIRXG+sv0ocm7mwwwkxOZLDYVF54kZxV3KNOkn3G0i0r86MgvQiLsFzdcrnIueDZgjUVpdaIc0fGIQhPVVqxUB/6OEfh+87nR5tcZTpq//1k1IMzZzPu/kMY5htvMJQEttgNhpJguGI8+R1ip8ScWPBI0d1twbNQUHyO96dEMSYkSTVE8dyvkKPdBfSEonzqgNwRLq7WaHFxMJFDbBw5sZirMpF2K7VchMehA2G4VUCcWbUbnIIpX7f2O/qhZz/HDSiCdQY/c9HstIVHZDAY/lnDFrvBUBLYYjcYSoLhpmxGWGcvqjsX19lXRjwoz6X1y8HlWB/LQXjbImLyUp/TSProogjp+tFosILTnSxjj4Qrz1lgD0Cj3dbejIP7z/Prh3X22PMn9gTY97Got9j+VIxEgx8XykcQjXQM1hgMhp8q2GI3GEqCIadsJi+KKFEmRvgQDEBZhioQHNGaqBOrHwcgPbCKIs+vsXrzVfBcMU++1VO+I4sEFCUFPflqNRnwEzKHcfNivs/iF8NNfRQx0cXMd9KDjpGKLINHf+k4M70ZDAZb7AZDWWCL3WAoCYZremPuslq15O6nedMH02PCqrKISstZcQqabmTwVi6cbWD/5NZGZ89o+bzjWkdfmc6ujxmsK0avS7uYrmAU2qOXPxMylXE4X5427XHuf16VU4cjrrQxCCJMUY6540a48/kkqJTNYddfr/fHbpG92Q2GksAWu8FQEgw3ZTMBm0a6ckZLpRxqZ56wItO/QZwUgJkmcr5iTLybGBsVVaOj3iTDRd1OSxJl1FlKo44S55pM9uswkaqShsX95aDiVnA7cpF5K+hCf1GYRCI4jOA44l54SvRl0jpXw5LIOyrRIjLrkx+nSSgER31Vi8+RSLdssByfdtS18P51im/+gZkfc6m0Y5F0S+eOTK+92Q2GksAWu8FQEgx9N34p4WnWDu9WpokWgfhuvC+PqdGPjXja44mxEVFXrbDMp9xbT4nx7cwf11LC6CIT8VtM7WgqkW1FW9EAViz/r3EXK0FS8JojSUbzVphQw8g1VtWWPqfQ5mW9o1+v+7Rimhqct9WidBKyIoXZrqGc90TKJq4WROJlcugsHWe78QaDwRa7wVAS2GI3GEqCoersbUd4q9lVKiadTPVD7HcnU3l3OR9Dyn6e2m2pP80z/bu+MCfqmMqOsTGv249XVKoppj9pva7NzXKCZEBGWq2URFGbWpYQIztYC+ScyVag9+ej7wJIw3s1axE511HpvtsspdTCQpjXnY+j3ZZ9cK+2VI2fk2VkfENC59RCWKHnLTMKt6OEz5WerKVzr4K8gohGiehRInqKiJ4jot/tfX8NET1CRIeI6OtEFMu3YDAYNhhFXhkNAB92zr0HwH4AdxDRLQC+AuAPnHPXATgP4O71G6bBYFgtiuR6cwCWZOJq788B+DCAz/a+vw/A7wD441hfKQFTVeqdWIq+Heb0n/egC0WgSGEiC6QtAqTHXo1dtj4Xz/baVmJ1K+NmFm7KU2KZEONFVZRbPE0G347lSPEhtSHmfaX5AFcmxq8wEiYUSbJSRCNcBgfF6LqxEflctVperNfZWZNAnx2EOe4GKE6+Dy6qd4r3USTbWdH87Gkvg+tpAA8CeBXAjHP9pGzHAOwp0pfBYNgYFFrszrmOc24/gL0A3gdgX9ETENE9RHSQiA4uzF1Y4TANBsNqsaxtXufcDIDvA7gVwGaifrb4vQCOB4651zl3s3Pu5vHJ6VUN1mAwrByX1NmJaAeAlnNuhojGAHwM3c257wP4VQBfA3AXgPsv1VcCh9Geya2lTp1UmA6vo58wWAfWUWncfNfJ6cMs4in1555vNUS7FtP5tPqXsjESN8foiC/xWV0LG1emddSAsrwc0xuF8oal4T5iaYgLI5+3etn9RbkxCvaRz0cgKv33+jiE91L455mZ86JudNSbcWs1r+svZ9sjyAev9gfkfo++Z0vkFeEzF7Gz7wZwH3UzySUAvuGc+yYRPQ/ga0T03wE8AeCrBfoyGAwbhCK78U8DuGnA94fR1d8NBsM/AwzVg67jgPn2UvonXelFpVSJnCF6hhpJTzsOp8Kw0sSL3cTMIh0VYcfP3G7p/pnpreP7byZhTrRKzCaSE/8DbZfBJ99BYCzL4BPXakm/XTRtkf482EyUu5JoaiV+HI8MCw4DLjeFgy9GawUJeyBTbY5teS+80VEdTcmfKx65qUXw8Lk5sgAZRvcj45fXqlcBvcF84w2GksAWu8FQEgydvKK6JPXEdph19sqAqKc910QXSnzjJAPtpt+B11I23/mvprHpYTx2UQpo7enEPO+0qJet/rc3NK1xKU+JhAH3t8yF1RVS7w2uHQlrSmQUFGHA4NTMsTRZmsI53E6LyOy5UjoJJz6pL0rVbnR8jH1iz9gyqKT5br9UYZVFyQV27dm5Y1dvb3aDoSSwxW4wlAS22A2GkmC4OjuA6pJ+G9NzA/pIt8Sj3sJmrVQp4yFCiUpFajmdDvdSUimEGVN9LJWQIM/UZkTeVh2YBBSuHCc786zSxySBedVeYdKspYybSYEQqlwfCoE8XXFPuHAdnyodeRYdR8Ez8c96vquM4ISc3oMZPFdZR++DhM+dMFunkxcq+4iZ7wp4GNqb3WAoCWyxGwwlwZDTPxHGR7rBJC4iKsaydHIRNsuZ1zi/vA6ICGQEVXxjXORMI0EVvBwTK3NCG5Pjc0QIBX96iafD0mI8J/Dg6kpVzrcMyJF9ZDEXNTEQMSjZf0isjPGa57zOmHge4V/jH3WASAi54B9EZWQ/RjV+7m3Ix1XJ3cuAqA45/5xTPnedwhNxMMm+ZXE1GAy22A2GssAWu8FQEgxVZ3fOobFE3kfKrMX1YW0KEooIJ5WUuiU5HoGkY+UGm++qSm/m5A+kFC/dp28npzHrhAkqopzyAYWLkti1SKS8jh2X02UFYYKsCmm9Wk/k48hbggb3EtO382powKQW2R/QLtRONmTfa72ZP0vKJMoeA7X1gZR4n7yPiLss6XnkhCmce764zl6E3MPe7AZDSWCL3WAoCYYqxgPMWyvmJaftGwGbV17oZeJcxI7FI+CSiIkuypLAoNNPi/60GB8oA0AWIJ6IBJvl54CrJQUtaEURm289V6EZ0fOR4+EL9CKo5GKmsZj5LnLeJGRXhRStK0plE48Ld36LmPZiZj/Rn3qEhYlRz0EBk6O92Q2GksAWu8FQEgxZjHf9HfS8h5sv6x3ViIQVbKdlXwrIWzmJMOKFFzyv3qUmvkutd3b5brzqJyCJLSuL61qkUAogNh/5sxb0oIuKn4Ed/agYTME6cVxkp1sHt7TaXIzXFhpGPME1KKVCxQJhQnXRYB01kUvZX428wmAw2GI3GMoCW+wGQ0kwdNNbX2ePerjpYwLkFQoyiizs7RXz/Irp8yHvt9yIBP+AqmV7CTnu8kDKZu0pGEVAZ4/p/YXTPUXbxdILhyH13GJ95KYUkXsWOI4iZi2938PV9FTp+hUW9iZSO0NFGRY0vQkPupxrYzgyz5v6wvNe+M3eS9v8BBF9s/f5GiJ6hIgOEdHXiVSydIPB8LbCcsT4zwN4gX3+CoA/cM5dB+A8gLvXcmAGg2FtUUiMJ6K9AH4JwP8A8J+oK8N+GMBne03uA/A7AP442g+AxA0W47kITjlvrIJifERyDPWRqVxHAeq03EferhLlKi9uCssC4nrsmjWCPHYxVaBYPM4liCFihiLeR3gc6Qpd/qQYvKIulCoQDjJJ9LPJeApT6aMX7j/K058VapcPhFlaV2EUfbP/IYDfZiPZBmDGObfEmH8MwJ6CfRkMhg3AJRc7EX0SwGnn3OMrOQER3UNEB4no4Pzc7Eq6MBgMa4AiYvxtAH6ZiD4BYBTAFIA/ArCZiCq9t/teAMcHHeycuxfAvQCw56p3rJ97l8FgiKJIfvYvAfgSABDR7QD+s3Puc0T0FwB+FcDXANwF4P4iJ1wimMiShvg+4znckjDne8qijtKmMq8xk4m2NPE8Yty9Ncl0FFMkIo670vJTK45w4bKZ04cj5BWhqLccv3x4Y6Goiy9Hpg4JppxTZiceeVVry4NGRrb0y4+98Fq/fPrcBdFu04g/bvsmOZBardovpzWWU60i0yaj4g1BYzXZx+SY7z/NFvrlTlPOdTvzfVAq67g5LFWkK9UkY2V/7najKdrJXG9yjO0O1/v9eFuaYIO1q6gHfClSdL3cZb+A7mbdIXR1+K+uoi+DwbDOWJZTjXPuIQAP9cqHAbxv7YdkMBjWA0PmoGsja5/pnjjZKeqIyZLkwqKpsHxUR+UJROC/Eom5CCoC4JQYz8SjTlH+uJz5Liyqx+pCZin9fVwVWAG0N1aALCPPd+dx4sw5Ufd3B77dL892vAiuUxnfcPXefnn79mtF3VsL9X75+Sdf7ZfrbTkfs3OL/fJ0Whd1v/65X2HjZ/OWSjUyJf8ctHNmMxpYBoAf/fif+uWf+7mf65c7JJ8rEZmn1LXZmRk//s1T/XJV2ZI7Ge9DYin9QczJ0XzjDYaSwBa7wVASDFWMvzh7Hg99968AANe+4xZRV2O77BcuSHv81MRkvzxSY7umYxOiXZTYIuHtIrvZnGK5oPjsKtJ6IDjucpaF0DjCHmoxnjxSu7KhgJdKINsokPfQS0O8E2oc/FwXL8yIuj27/G68O3PR91Gpinan33y5X/5/J14XdXPzfve80fL3oq0DiFL/7DSUxSBlc7qw4J+rRust0a6dtvvliZFdoo4EfbnScZgFqNnw420n48F2ibrP4xN+/M8+/agfb0NaLnbs2N0vb98ufdhqIz3xP8SAAnuzGwylgS12g6EksMVuMJQEQ9XZW80W3nyj61W7d+9rom77Fq+PPPvkj0TdjTfs65drI5v65csmrxDtFue9CYaUrlytcl3R/8YtNhdFu4RHxCndKmVMC6Mj3pyU4/fOuLeU7GOC7TPMXJA6WYXp/lw/HqlKj7GtW7f2y+12W9SNjXtzZKPhzUu1mkpRlXEdWJneRvxcca8tHWlVZbmQrti+Q9TtnWK6bNuPd9dll4l2b7zu9fTFudOi7izT9cfGuQ4s9w7qzfl+eWq7fCbOH/9hv/zKy0/0y6feOibbLXgd/iO3flrU8XuhzaBXbfV7SJ0Z7zF+/qJMBV5lDBhVterq9bl++fiRZ/rlNqQZ8fyZo/1y48rrRV0t7e5rNesLCMHe7AZDSWCL3WAoCYYqxlPikI52xc4XXnpO1L12+JV+uVmXovVPHvPmiKv2ejHttddPiHYJebFSSbcAy/DKecEr41LcX1z0566kcnqqLDCjymWxlhTtuEmq1ZbiHDej7b/pvaLumaef7pdHRrzoXlVyX3LkSL/c6UhTED83L7c7ckJ4plmd0rG35rgAABdMSURBVIhzqXGBuaNEWNFO8bb969tu7Zcv27W9Xz52TAZHHnv1qX55PJX3vdLw4nmVmbIS5VnG/ShpVoqxp054UfiKTdP98uEn3xTtOpm/ls65w6KuwYJazs+cF3V8jqfpyn55fE566FE17KF37tyZfjlbPNsvzzD1BJDBO1du3yzq4HrjymQAjhhrsMZgMPxUwRa7wVAS2GI3GEqC4ers5DDS09nPnz8j6nbv9C6KjqR+OTHltbKXXvUEt1ftkVFSH/34L/fL6cQWUddMvA6cJV73fuzgI6Ld7R9lkUsqumqEkSa0W36M20blNC7Oe72OEqmHNuve3PbDh78t6m669WP98vSmd/bLyYiKfgLjJ6+Mibqs7XW2zrzXV6enpkS7c4wibGxKunYmzCWUm+80EWjGNkZ++N0Dou7igh/jmZde9H23pR76+iue7exTd/6SqJud8+OvjnmX6ZPHpd5/7eXenPfGKamLZ4xcYmLc36dP/uKHRbvTp73Zb+smGU05ttM/S29NSHffsTE//40GM5VNyGc4YaGEmnN9esTXXbHN99c5Kl2Qf/6DH+qXx5Wr+MW5rvmukobf3/ZmNxhKAlvsBkNJMFQxvlqpYPe2bQCAVPE0zF30Ys/8rDQfLFS8GDsx7s0452elB9pPHvdEAk1lktq5w6sJxDzVtqdSZFs44UVEUqa30c3e3DE/48Xgh5+Q9HsTY17Ua7WkGD/ORP7KiBRpF+b99WyZ8nPQbsr5GJ/y6sSMijZ7+EdsDua8GWrnLhnJdcO7b+yXG+cvirpx5rFXYSpPQ3kbchH28NFXRF277T3Sxpl5c5cSkT/3aU8uofMcH3/zjX55287L++XRESkIn2Sie5ZJ8bnCvPwaDT/+8XGpuoyO+j6bTcWPyLjhx8el2rSwMNhjTROwXDjv7+34hDz32Ij/fNl2r5Ls3HG5aMe98JpN6V3X6ZlBY6m87M1uMJQEttgNhpJguLvxINQ63VNWa1JkazDRKVXblbUxP8yk6sWjuboUb5965if98s+//z2ibqzpve0qzBMpS6ZFu8WTfid9oS1VgbdO+IHNXPRi/Nnzh0S7mQtedMxaUqzazcTpi7NSfD7JxNad267ql594+seiXca84S7f805Rt7DoxcrJTX7HlqrSU/Cpp73n2juvvVrUTYwzgpCafx88/I8PinYvH/K77CNVeT8Xm4zCmXnojY7tFu1adT8HF+almnDddd7acuJN71mmOUqmJrxqMKlE/FOnTvXL3ItwUXlpTjDRutWS973JnpdUkYA4ZqHgpCucaAIAzrIglvEF+dy2mJpGPA1aVY6j1fKie2NRemYuBX5lHe066mFvdoOhJLDFbjCUBLbYDYaSYLg6u0tArks+UatJwr9dl3mz1tlzZ0Vdk3ldcU+kZksRMTImwnmlF3WYra9KnLjhpGg3nnpPs4lNm0TdsRNH+uXDR7wOVp2QHPg1RqqYKI+mC+f8uc+ekTrZ6Ki/7nMnvf5evyDn48wpP+bzJ6T58eO/8tl+efYi2xNQZJGTY15HfeKfpC7eYJeTstRKnbYklzj/lp+DffveJep27PJkFo8/7qMWW0pXnhr3+wpjY5Kk4+KCJ3VwzDNwYkJ6j51hUWPVEdlHhUWbzTJT7fS03KtptXz/iwvSrDU763XxyclJUcdJUc6c8fdlkxrjFXu8Se3iRblXM7XFP3MLjGTT5dJQMdJKlYaq0YvWjKXELpqf/QiAi+gmI2s7524moq0Avg7gagBHAHzaOXc+1IfBYNhYLEeM/5Bzbr9z7ube5y8COOCcux7Agd5ng8HwNsVqxPg7AdzeK9+Hbg64L8QOaLYzHD/ZFTemL9sm6i7MeBFrblb+Bl1kZoYxFoiw7+rrRLvRUW+C+eHBZ0Xd+97n09JNT3kRrt2SJgw37uvSURk8smWbF8XePek90GbmpErSYF5VKclrmZv1Hm9bt0rxH0wtOXfKi6Z7d8p2V1/mzTrH3pgTdXXmDVdnPOaaT68549u156Un35YJ76V4bsaL3e++7ibR7vpr/lW//NZbUsQ/dsJzDCZVrw49f0QSjpy74Pu/8VrJT7dlzB9XY+QjzbryHmMebu1FeS2cD5CrCXXF1ca9AXkKJkB64Y0oNYF70L2DmQpbqv8mM69t26aCks751FnVGiNWqUlvQ86Pn0ktoZ/2SROdiOODNaovAN8loseJ6J7ed7ucc0t37iSAXYMPNRgMbwcUfbN/wDl3nIh2AniQiF7klc45RzQ4FUXvx+EeAKjVRgY1MRgMQ0ChN7tz7njv/2kAf4NuquZTRLQbAHr/TweOvdc5d7Nz7uZKRMQwGAzri0uuPiKaAJA45y72yr8A4PcAPADgLgBf7v2/P9xLF9XqCHbt7ZLynT0r9dz6vB/KRE3q85vGvA7JObzPnJab/1xnn5zeKupeP+Z1xfFzfn9gx5Q0SbUWvP7UVKa3w4c9EeGVV3pywcunZCTU5fuu6Zf37t0r6iTZgYyuWmQuuHWml4byt3X7k6mSiel81U5Y1+RX/S/ff5uo2zHq9zEmJ7xO/cKhl0W7GWaSeuOE/K2fucjytM37cWyekvssey6/wY93VOYvw7gfc23cC46NxinRbHLak0uMtKQ+v8jmscpSa1cr0q20XvfzODsvXWK3b/PPn1Mu1BkjOGnW/fOYdqS+zflYLpyVkYpjLPV4h/XfqEthud3x94IThgL+GQnlCwSKifG7APxNb5FVAPxf59y3iegxAN8gorsBHAXw6UgfBoNhg3HJxe6cOwzgPQO+PwfgI+sxKIPBsPagWLD7WmN8csK9s0eaUK1IMafZ8iKtllpnmblqbMwfd91VV4p2PFXyrPJSuoKJ09x7akRFFnFSg/3794u6DhOdON9Y1pIiIeee1+mZ+HzrPYys02LlMK877//xJ54WdT983EfgcV53rQpwT6vPfOpOUXf7bf66j7/piSFqNRlR1m76/l85KkX8U8wU12DRifNzUszmm7Yzs9KMeOKkF9epw6LBOlLMrpAf14gix9hzmVcNtm31BqNtmyXv+ugoJ7lQ6ZzZszk1KW1eJ096spMK041UFm9Mb/Yq4YkTkicPzBuOpwBzKgqQp9bWKuCSae+Bh17A2fPzA5OXm2+8wVAS2GI3GEoCW+wGQ0kwVMN3mgBLFOXnz0uT0fHjPsprclIS8tVG/DCnWTTRO66Q7pU7mVvp3j3SjLN1mzfnLTIXxwsXpRlkbs7rja8delXUhUxgpCLKuF4uU0VLHT6mz29iZr9ZldqZW1defVWNseHbVpheXl+UuvLUtHfZ7LSki+lLh72r67ve6U1jx147KtolbLw3XnuDqPuZff7z4df8PsKTTz4u2m1mXO515bq850pvPt17mc/x9+qhN2S73X7v5sibcow/ec6naa7AR6y5tlSq04TlYksUaSXTo6enZNTbjq1e99+x3Y93k+LiP9fwz0g6fbWoa7X88zhT9/eiqZiY+J7JvGLTGRnprgtHarOAwd7sBkNJYIvdYCgJhmp627Fjq/s3/7ab4mh6eruo27nTf960SYpKO1nK361bvah0/NBrot0FJu7WVWQUJwrkZieXSBGci+qaXJCDz5ueQVGnKnlUkiYaaDSkGNs/piJVAU6IoftoMTNgjMiAi4RpTfbPiS5aLF3xze+VKaZfP/J6v6wyQ6HZ9OOo1nx/lGSqnb9PTzwtuecf+uEP+uWdu7y59PKrpHfk5LQ3t507dUzUXb7Li/gHH/Ukm7fcLL0GTzNCkGdel56Z5xnnOzJl1WJmwIRxxTtSEWvsOdPqYJVF1XH1bXyLVAX4s69JNJae1b/7+tdx9vQpM70ZDGWGLXaDoSQYqhh/3XXXut//n78HAGjUpch69OiRfrmTyTruCcYjaZ3ckBTidLUSNjTwHfIEUqzkO+t6boJzpcV9JkQliryiybjOcmI2S7XEx6F3+/nnTkcHZjAvPK6uRO7z2KjKBMu6rLC56qgo5hve5XnnOiod0dnTMlhlCWo6hFdYoobo2PnemvHWm2dekMQkbZby6dDx10XdJCPAqHOiiWtlgNLIKOMGPC85/xZYRtrUSQ+6o6968X9i1O/MX1iQVp5W0/dPkGpTh3kHgpF0ZFD3lnlV6vu+ZNmZOXsKrVbTxHiDocywxW4wlAS22A2GkmCoOvvu3bvc3Xd/BgCQ5AxWHlpH1VFfoXbcpBGr47ps4pTZielJDjr9L9ej/fdtJ6PBuD6ldSv+WevsRGwvgY1Xm2p4H07bvPj4hQlQzjefn2pVEVswb7KYKZLX7b3qalE3Ne3112NHvQddQnK8rsNIOkjf54GqZ1BfBYA3z0oSjcd/4vP/zS147zSVURljLJqteUGa3hYanvzz2msk+cbpk97j8vob/D4AkSSc5Dp7oy5Pfux13/+5cz5ac3FBRSqyNZPLR9cj0Zg5exatVst0doOhzLDFbjCUBEMW43e6u+7qslelStDgImKiTU1MXBTkD1q8Z3U6yISbkEIiPSDF2xxZA+MH27dvX7985pwM6jl2zAdqUC4wISxa12reY4pPgb5FfMxZJsU55wZ70Glxn/cZF+P5+OVA+D3rqDFeeZVPOX3dO3z58cceEe1qjPEhTeRchZ7NWOBRUwXT8DlosXTGL778kmj32MGDvj91MTfc6IOqrrryGlF35LAXwccn2bVUpemNqyhpok2d/roXWY6ENJEciBm7zjNn5TP34stdVenE62fRqJvpzWAoNWyxGwwlgS12g6EkGCp5hXNev6IIAaJTOlkacB3VejnvQ5tniPlpupTpZKnS2ROvpztIHfKWW32k1IED3++XK9WwPpznuwi7wUqTmlt2uy4Gu8h2FM84nyu9r5DoDZXguXidMicd9W6rGXMR/vnbPyTaHTjwD/3yWE1O1uBRAJ2O1Mv5vsJ4Kk2pTcdIN9kzcOP1kmzjxnf6PZjZWdn/Dx7+Vr/sWjJXXdb2+x0Zs3hVanr/gY2pJYkkOXGGg5+r2TlJWjLFIuImJ+Xz/a53XQ4AOH9aHsNhb3aDoSSwxW4wlARDT762JApqETwJmNeAMP+5Fm+l+U6pCY57zfm6TibFrXf/zM/0y8ePS5HtH773PX9uNg6ejnfQuCQ4iYFux8VuFdLHWwnPOG06HNxHzKNQ9yG8/ByP1gqrE6k2MbKQxGPHPKFEps71sV/4RL/8ve9+W46RRw+m/H7Ke8tNoqT6z4S5kJnGlDcgv5apCWny+vgvfrxfnrso+fpeftHzxrdZiuzpLTLNNifp2L1b1p08xVKTjXs1crSiuOHZOmi3ZZThdI/zLk3D7+9Cb3Yi2kxEf0lELxLRC0R0KxFtJaIHieiV3v8tl+7JYDBsFIqK8X8E4NvOuX3opoJ6AcAXARxwzl0P4EDvs8FgeJuiSBbXaQAfBPDvAMA51wTQJKI7Adzea3YfgIcAfCHWl3OuL75rcSsmxnNPOe5FlEbEZUrDXlabt/ggjX3/QvKqfec732HnkqpGmg7eIU+UeBsT43ldpvnMMDiARmfmlDv8+jq5dx2fY9kH7zPRrBHc+sHOpUV1YnK2c9qTj1lNmIXg+JuS1OKhH/yoX/7Qhz4q6n78o4f7Za7K6eeDz2NTB9qw+egERHoAcOx5IaVCJUw12jwtRfz9+3/Wn7vld8LPzchUVqfOea/K0ZpS0TLPV8enWEvkYyOctERWLix0Rf5YFtcib/ZrAJwB8H+I6Aki+t+91M27nHNLysZJdLO9GgyGtymKLPYKgPcC+GPn3E0A5qFEdtf9qR34k0JE9xDRQSI6uKgSFRgMhuGhyGI/BuCYc24pguEv0V38p4hoNwD0/p8edLBz7l7n3M3OuZt5BlaDwTBcFMnPfpKI3iCiG5xzL6Gbk/353t9dAL7c+39/gb76ulc+4ot5rikZgevE3PzjtHmN1WXKY+wDH/hAv8xTJv39t/5WtOP7A1Wdd5dBmMZSGR3HdV6X06lZH22tG7KItYgZjpg+rE2MacWPhXuuOSV4ifl3Ec81pg+3lF7OiTvl7obsQxB9KDPlmRPe7PT3P3hU1N122+398huv+Si1N48cEu1qxE1vyjzIyknmr7Otoh25Ka6dyDECfk51dF+W+rbE2m3ZIlNC81wI2uw8c97r93xPZ3JKGrhmLngizJExGak4t7DklRfW2Yva2f8jgD8johqAwwD+PbpSwTeI6G4ARwF8umBfBoNhA1BosTvnngRw84Cqj6ztcAwGw3ph6B50IXAShopKd8RFTiFuKXHoyit9qp8rrrhC1D344IP9Mk/BFONk155xIfMgadNVoL9L1XGzogxUUZ6CLPAjFyTD5kR7q4XQbMrAD84JwvvXXmf8OD6nQHHiCT6nb52S2VkfZCrWJ+64o1+eVCLsU0/4TK3jI2HVi59ak34IspCIKJzvc/D9jV2nnse9ez13HX/mFhalt94bRz1H/fiEnIPFxa7prdMO33PzjTcYSgJb7AZDSWCL3WAoCYZKOLlz53b3qU99sntipepobnQOaZZj5IJNneLY142Py5xczaaPIIrqw5E0zcGIO5J7DNw82MmKRa/F6riJC4hHxHFIYkrlRsq581O1dUODTXv6vKH70u1isK7fag1OSw0AFVKRkMz0OTnl0xXf9sHbRbtFlqb64MP/KPtgt5MTmZK6LzwCsdnRhsQwQvewrXjdo/ci0EenLZ/FxbrnlNc5DZ5/7kUAwKOPPoPZ2TkjnDQYygxb7AZDSTBUMZ6IzqDrgLMdwNlLNF9vvB3GANg4NGwcEssdx1XOuR2DKoa62PsnJTronBvkpFOqMdg4bBzDHIeJ8QZDSWCL3WAoCTZqsd+7QefleDuMAbBxaNg4JNZsHBuisxsMhuHDxHiDoSQY6mInojuI6CUiOkREQ2OjJaI/IaLTRPQs+27oVNhEdAURfZ+Iniei54jo8xsxFiIaJaJHieip3jh+t/f9NUT0SO/+fL3HX7DuIKK0x2/4zY0aBxEdIaJniOhJIjrY+24jnpF1o20f2mKnbkKx/wXg4wBuBPAZIrpxSKf/UwB3qO82ggq7DeC3nHM3ArgFwG/05mDYY2kA+LBz7j0A9gO4g4huAfAVAH/gnLsOwHkAd6/zOJbweXTpyZewUeP4kHNuPzN1bcQzsn607c65ofwBuBXAd9jnLwH40hDPfzWAZ9nnlwDs7pV3A3hpWGNhY7gfwMc2ciwAxgH8BMD70XXeqAy6X+t4/r29B/jDAL6JLqPVRozjCIDt6ruh3hcA0wBeQ28vba3HMUwxfg8Azk5wrPfdRmFDqbCJ6GoANwF4ZCPG0hOdn0SXKPRBAK8CmHGuT5Y/rPvzhwB+Gz797LYNGocD8F0iepyI7ul9N+z7sq607bZBhzgV9nqAiCYB/BWA33TOzW7EWJxzHefcfnTfrO8DsO8Sh6w5iOiTAE475x4f9rkH4APOufeiq2b+BhF9kFcO6b6sirb9UhjmYj8OgHNF7e19t1EoRIW91iCiKroL/c+cc3+9kWMBAOfcDIDvoysubyaipXjXYdyf2wD8MhEdAfA1dEX5P9qAccA5d7z3/zSAv0H3B3DY92VVtO2XwjAX+2MAru/ttNYA/BqAB4Z4fo0H0KXABgpSYa8W1A3y/iqAF5xzv79RYyGiHUS0uVceQ3ff4AV0F/2vDmsczrkvOef2OueuRvd5+J5z7nPDHgcRTRDRpqUygF8A8CyGfF+ccycBvEFEN/S+WqJtX5txrPfGh9po+ASAl9HVD//rEM/75wBOAGih++t5N7q64QEArwD4BwBbhzCOD6Argj0N4Mne3yeGPRYAPwvgid44ngXw33rfXwvgUQCHAPwFgJEh3qPbAXxzI8bRO99Tvb/nlp7NDXpG9gM42Ls3fwtgy1qNwzzoDIaSwDboDIaSwBa7wVAS2GI3GEoCW+wGQ0lgi91gKAlssRsMJYEtdoOhJLDFbjCUBP8fB75rjlwyrygAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Random plot image\n",
        "idx = np.random.randint(0, X_train.shape[0])\n",
        "test_image = X_train[idx]\n",
        "print(\"Label: {}\".format(LABEL_NAMES[y_train[idx].argmax()]))\n",
        "print(\"Image shape: {}\".format(test_image.shape))\n",
        "\n",
        "plt.imshow(test_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p66Jn2bQrlU_"
      },
      "source": [
        "# Define utils function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "X3jIae7Br8OF"
      },
      "outputs": [],
      "source": [
        "# Nomalize preprocessor \n",
        "class NomalizePreprocessor:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def preprocess(self, image):\n",
        "\n",
        "        # Normalize image in range [0, 1]\n",
        "        image = image.astype(np.float32)\n",
        "        image = (image - 127.5) / 127.5 \n",
        "\n",
        "        # Normalize image in range [0, 1]\n",
        "        # image = image.astype(np.float32) / 255.0\n",
        "\n",
        "        return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qfdNbUcpwfaY"
      },
      "outputs": [],
      "source": [
        "def PredictGenerator(X, batchSize, preprocessors = None):\n",
        "\n",
        "    N = X.shape[0]\n",
        "\n",
        "    for i in np.arange(0, N, batchSize):\n",
        "\n",
        "        images = X[i: i+batchSize]\n",
        "\n",
        "        if preprocessors is not None:\n",
        "            procImages = []\n",
        "\n",
        "            for image in images:\n",
        "                for p in preprocessors:\n",
        "                    image = p.preprocess(image)\n",
        "\n",
        "                procImages.append(image)\n",
        "            \n",
        "            images = np.array(procImages)\n",
        "\n",
        "        yield images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "i2pErhtprnVG"
      },
      "outputs": [],
      "source": [
        "def DatasetGenerator(X, y, batchSize, preprocessors = None, aug = None):\n",
        "\n",
        "    N = X.shape[0]\n",
        "\n",
        "    while True:\n",
        "\n",
        "        # loop over dataset\n",
        "        for i in np.arange(0, N, batchSize):\n",
        "\n",
        "            images = X[i: i+batchSize]\n",
        "            labels = y[i: i+batchSize]\n",
        "\n",
        "            # check to see if our preprocessors are not None\n",
        "            if preprocessors is not None:\n",
        "\n",
        "                # initialize the list of processed images\n",
        "                procImages = []\n",
        "\n",
        "                # loop over the images\n",
        "                for image in images:\n",
        "                    # loop over the preprocessors and apply each to the image\n",
        "                    for p in preprocessors:\n",
        "                        image = p.preprocess(image)\n",
        "\n",
        "                    # update the list of processed images\n",
        "                    procImages.append(image)\n",
        "                \n",
        "                # update the images array to be the processed images\n",
        "                images = np.array(procImages)\n",
        "\n",
        "            if aug is not None: \n",
        "                (images, labels) = next(aug.flow(images, labels, batch_size=batchSize))\n",
        "\n",
        "            # yield a tuple of images and labels\n",
        "            yield (images, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zMcTU6gdphyJ"
      },
      "outputs": [],
      "source": [
        "def Predict_Encoder_Classifier(encoder_model, classifier_model, X, batchSize, preprocessors = None):\n",
        "\n",
        "    predict_labels = np.zeros(shape=(1, NUM_CLASSES))\n",
        "\n",
        "    N = X.shape[0]\n",
        "\n",
        "    for i in np.arange(0, N, batchSize):\n",
        "\n",
        "        images = X[i: i+batchSize]\n",
        "\n",
        "        if preprocessors is not None:\n",
        "            procImages = []\n",
        "\n",
        "            for image in images:\n",
        "                for p in preprocessors:\n",
        "                    image = p.preprocess(image)\n",
        "\n",
        "                procImages.append(image)\n",
        "            \n",
        "            images = np.array(procImages)\n",
        "\n",
        "        predicts = classifier_model(encoder_model(images))\n",
        "\n",
        "        predict_labels = np.concatenate((predict_labels, predicts))\n",
        "    \n",
        "    return predict_labels[1:] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xhMmDavKamr"
      },
      "source": [
        "# Adversarial discriminator domain adaptation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "u3h_OXrR_P-Y"
      },
      "outputs": [],
      "source": [
        "# custom activation function\n",
        "def custom_activation(output):\n",
        "\tlogexpsum = backend.sum(backend.exp(output), axis=-1, keepdims=True)\n",
        "\tresult = logexpsum / (logexpsum + 1.0)\n",
        "\treturn result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4_bYiUyHkaOa"
      },
      "outputs": [],
      "source": [
        "class ADDA():\n",
        "    def __init__(self, source_lr=0.001, disc_lr=0.0002):\n",
        "        \n",
        "        # Input shape \n",
        "        self.img_rows = IMAGE_SIZE\n",
        "        self.img_cols = IMAGE_SIZE\n",
        "        self.channels = IMAGE_CHANNEL\n",
        "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "\n",
        "        self.src_flag = False\n",
        "        self.tgt_flag = False\n",
        "        self.disc_flag = False\n",
        "        self.classifier_flag = False\n",
        "\n",
        "        self.src_optimizer = Adam(source_lr)\n",
        "        self.disc_optimizer = Adam(disc_lr, beta_1=0.5, beta_2=0.9)\n",
        "\n",
        "        self.num_outputs = NUM_CLASSES\n",
        "\n",
        "        self.feature_map = 32\n",
        "\n",
        "    def define_source_encoder(self, weights=None):\n",
        "        \n",
        "        self.source_encoder = Sequential()\n",
        "        self.source_encoder.add(Input(shape=self.img_shape))\n",
        "\n",
        "        self.source_encoder.add(Conv2D(self.feature_map, (4,4), strides=(2,2), padding=\"same\"))\n",
        "        # self.source_encoder.add(BatchNormalization())\n",
        "        self.source_encoder.add(ReLU())\n",
        "\n",
        "        self.source_encoder.add(Conv2D(self.feature_map * 2, (4,4), strides=(2,2), padding=\"same\"))\n",
        "        # self.source_encoder.add(BatchNormalization())\n",
        "        self.source_encoder.add(ReLU())\n",
        "        \n",
        "        self.source_encoder.add(Conv2D(self.feature_map * 4, (4,4), strides=(2,2), padding=\"same\"))\n",
        "        # self.source_encoder.add(BatchNormalization())\n",
        "        self.source_encoder.add(ReLU())\n",
        "\n",
        "        self.source_encoder.add(Conv2D(self.feature_map * 8, (4,4), strides=(2,2), padding=\"same\"))\n",
        "        # self.source_encoder.add(BatchNormalization())\n",
        "        self.source_encoder.add(ReLU())\n",
        "        \n",
        "        self.src_flag = True\n",
        "\n",
        "        if weights is not None:\n",
        "            self.source_encoder.load_weights(weights, by_name=True)\n",
        "    \n",
        "    def define_target_encoder(self, weights=None):\n",
        "        \n",
        "        if not self.src_flag:\n",
        "            self.define_source_encoder()\n",
        "        \n",
        "        with tf.device('/cpu:0'):\n",
        "            self.target_encoder = clone_model(self.source_encoder)\n",
        "            self.tgt_flag = True\n",
        "        \n",
        "        if weights is not None:\n",
        "            self.target_encoder.load_weights(weights, by_name=True)\n",
        "\n",
        "    def define_classifier(self, weights=None):\n",
        "\n",
        "        inputShape = self.source_encoder.output.shape[1:]\n",
        "\n",
        "        self.classifier = Sequential(name=\"Classifier\")\n",
        "        self.classifier.add(Input(shape=inputShape))\n",
        "\n",
        "        self.classifier.add(GlobalAveragePooling2D())\n",
        "        self.classifier.add(Dense(100, activation=\"relu\"))\n",
        "        self.classifier.add(Dropout(0.5))\n",
        "        self.classifier.add(Dense(self.num_outputs, activation=\"softmax\"))\n",
        "\n",
        "        self.classifier_flag = True\n",
        "        self.classifier.summary()\n",
        "\n",
        "        if weights is not None:\n",
        "            self.classifier.load_weights(weights, by_name=True)\n",
        "\n",
        "\n",
        "    def get_encoder_and_classifier(self, weights_classifier=None):\n",
        "        \n",
        "        if not self.classifier_flag:\n",
        "            self.define_classifier(weights_classifier)\n",
        "\n",
        "        input = self.source_encoder.inputs\n",
        "        output = self.classifier(self.source_encoder.outputs)\n",
        "\n",
        "        encoder_classifier_model = Model(inputs=input, outputs=output, name=\"encoder_classifier\")\n",
        "        \n",
        "        return encoder_classifier_model\n",
        "\n",
        "    def define_discriminator(self, encoder_output_shape, hiddens_3 = NUM_CLASSES):\n",
        "\n",
        "        inp = Input(shape=encoder_output_shape)\n",
        "\n",
        "        x = Conv2DTranspose(self.feature_map * 4, (4, 4), strides=(2,2), padding=\"same\")(inp)\n",
        "        # x = BatchNormalization()(x)\n",
        "        x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "        x = Conv2DTranspose(self.feature_map * 2, (4, 4), strides=(2,2), padding=\"same\")(x)\n",
        "        # x = BatchNormalization()(x)\n",
        "        x = LeakyReLU(alpha=0.2)(x)\n",
        "        \n",
        "        x = Conv2DTranspose(self.feature_map, (4, 4), strides=(2,2), padding=\"same\")(x)\n",
        "        # x = BatchNormalization()(x)\n",
        "        x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "        x = Conv2DTranspose(IMAGE_CHANNEL, (4, 4), strides=(2,2), padding=\"same\")(x)\n",
        "        # x = BatchNormalization()(x)\n",
        "        x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "        x = Flatten()(x)\n",
        "\n",
        "        x = Dense(hiddens_3, name='discriminator3')(x)\n",
        "\n",
        "        # Define unsupervised discriminator model\n",
        "        d_out_layer = Lambda(custom_activation)(x)\n",
        "        self.discriminator_model = Model(inputs=(inp), outputs=(d_out_layer), name='unsupervised_discriminator')\n",
        "\n",
        "        # Define supervised discriminator\n",
        "        c_out_layer = Activation(\"softmax\")(x)\n",
        "        self.supervised_discriminator_model = Model(inputs=(inp), outputs=(c_out_layer), name=\"supervised_discriminator\")\n",
        "\n",
        "        self.disc_flag = True\n",
        "\n",
        "\n",
        "    def get_whole_encoder_and_discriminator(self, encoder, weights=None):\n",
        "        \n",
        "        if not self.disc_flag:\n",
        "            self.define_discriminator(encoder.output_shape[1:])\n",
        "        \n",
        "        disc = Model(inputs=(encoder.input), outputs=(self.discriminator_model(encoder.output)))\n",
        "        \n",
        "        if weights is not None:\n",
        "            disc.load_weights(weights, by_name=True)\n",
        "        \n",
        "        return disc\n",
        "\n",
        "    def train_source_model(self, model, epochs=TRAIN_SOURCE_EPOCHS, batch_size=BATCH_SIZE, save_interval=1):\n",
        "\n",
        "        if not os.path.isdir('model'):\n",
        "            os.mkdir('model')\n",
        "\n",
        "        ((X_train, y_train), (X_validation, y_validation), (X_test, y_test)) = get_dataset(src_dataset)\n",
        "\n",
        "        # Preprocess\n",
        "        normPro = NomalizePreprocessor()\n",
        "\n",
        "        # Dataset generator\n",
        "        trainGen = DatasetGenerator(X_train, y_train, batchSize=batch_size, preprocessors = [normPro])\n",
        "        valGen = DatasetGenerator(X_validation, y_validation, batchSize=batch_size, preprocessors = [normPro])\n",
        "\n",
        "        # Early stopping\n",
        "        earlyStoppingCallback = EarlyStopping(monitor='val_accuracy', mode='auto', min_delta=0, patience=5, restore_best_weights=True)\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=self.src_optimizer, metrics=['accuracy'])\n",
        "        model.summary()\n",
        "\n",
        "        N_train = X_train.shape[0]\n",
        "        N_val = X_validation.shape[0]\n",
        "\n",
        "        STEPS_PER_EPOCH = N_train//batch_size\n",
        "        VAL_STEPS = N_val//batch_size\n",
        "\n",
        "        model.fit(trainGen, \\\n",
        "                steps_per_epoch = STEPS_PER_EPOCH, \\\n",
        "                validation_data = valGen, \\\n",
        "                validation_steps = VAL_STEPS, \\\n",
        "                epochs = epochs, \\\n",
        "                callbacks=[earlyStoppingCallback], verbose=1)\n",
        "        \n",
        "        # Evaluate on testing dataset\n",
        "        testGen = PredictGenerator(X_test, batchSize=BATCH_SIZE, preprocessors = [normPro])\n",
        "        y_test_predict = model.predict(testGen)\n",
        "\n",
        "        print('---CLASSIFICATION REPORT ---')\n",
        "        print(classification_report(y_true=y_test.argmax(axis=1), y_pred=y_test_predict.argmax(axis=1)))\n",
        "    \n",
        "        # Save classification model\n",
        "        model.save(os.path.join(\"model\", \"source_classification.h5\"))\n",
        "        \n",
        "        # Save source encoder model \n",
        "        source_encoder = Sequential()\n",
        "        source_encoder.build(self.img_shape)\n",
        "\n",
        "        for layer in model.layers[:-1]:\n",
        "            source_encoder.add(layer)\n",
        "\n",
        "        source_encoder.save(os.path.join(\"model\", \"source_encoder.h5\"))\n",
        "\n",
        "        # Save classifier model\n",
        "        classifier_model = Sequential()\n",
        "        classifier_model.add(Input(source_encoder.output_shape[1:]))\n",
        "\n",
        "        for layer in model.layers[-1:]:\n",
        "            classifier_model.add(layer)\n",
        "\n",
        "        classifier_model.save(os.path.join(\"model\", \"classifier.h5\"))\n",
        "\n",
        "    # ====================================================================================\n",
        "\n",
        "    def train_target(self, epochs=ADVERSARIAL_EPOCHS, batch_size=BATCH_SIZE, save_interval=1,\n",
        "                    test_images=None, test_labels=None):\n",
        "\n",
        "        # 1. Load dataset and define preprocessing method\n",
        "        ((X_train_source, y_train_source), (X_validation_source, y_validation_source), (_, _)) = get_dataset(src_dataset)\n",
        "        source_image = np.concatenate([X_train_source, X_validation_source])\n",
        "        source_label = np.concatenate([y_train_source, y_validation_source])\n",
        "\n",
        "        ((X_train_target, y_train_target), (X_validation_target, y_validation_target), (_, _)) = get_dataset(tgt_dataset)\n",
        "        target_image = np.concatenate([X_train_target, X_validation_target])\n",
        "\n",
        "        normPro = NomalizePreprocessor()\n",
        "\n",
        "        # 2. Define target encoder (if it doesn't exits)\n",
        "        if not self.tgt_flag:\n",
        "            weights = os.path.join(\"model\", \"source_encoder.h5\")\n",
        "            if os.path.isfile(weights):\n",
        "                print(\"[INFO]: target_encoder is copy from {}\".format(weights))\n",
        "                self.define_target_encoder(weights)\n",
        "            else:\n",
        "                self.define_target_encoder()\n",
        "        \n",
        "        # 3. Compile supervised discriminator model and unsupervised discriminator model\n",
        "        self.supervised_discriminator_model.compile(loss='categorical_crossentropy', optimizer=self.disc_optimizer, metrics=['accuracy'])\n",
        "        self.supervised_discriminator_model.summary()\n",
        "\n",
        "        self.discriminator_model.compile(loss=\"binary_crossentropy\", optimizer=self.disc_optimizer)\n",
        "        self.discriminator_model.summary()\n",
        "\n",
        "        # Build adversarial model by setting the discriminator to *not* be trainable\n",
        "        self.discriminator_model.trainable = False\n",
        "\n",
        "        whole_target_disc_model = self.get_whole_encoder_and_discriminator(self.target_encoder)\n",
        "        whole_target_disc_model.compile(loss=\"binary_crossentropy\", optimizer=self.disc_optimizer)\n",
        "        whole_target_disc_model.summary()\n",
        "\n",
        "        # 4. Loop through epoch\n",
        "        for epoch in range(0, epochs):\n",
        "            \n",
        "            print(\"-----[INFO] starting epoch {} of {}...\".format(epoch, epochs))     \n",
        "\n",
        "            # Calculate accuracy (for testing purpose)\n",
        "            if epoch % 2 == 0:\n",
        "\n",
        "                # Checkpoint target_encoder\n",
        "                file_name = \"target_encode_{}.h5\".format(epoch)\n",
        "                self.target_encoder.save(os.path.join(\"model\", file_name))\n",
        "\n",
        "                # Load classifier model\n",
        "                classifier_model = load_model(\"/content/model/classifier.h5\")\n",
        "                \n",
        "                # Predict\n",
        "                normPro = NomalizePreprocessor()\n",
        "                predict_labels = Predict_Encoder_Classifier(self.target_encoder, classifier_model, test_images, batchSize=batch_size, preprocessors=[normPro])\n",
        "\n",
        "                # Calculate accuracy\n",
        "                accuracy = np.sum(predict_labels.argmax(-1) == test_labels.argmax(-1)) / len(test_labels)\n",
        "                print(\" * Accuracy at epoch {}: is {}\".format(epoch, accuracy))       \n",
        "            \n",
        "            # Update learning rate of discriminator \n",
        "            if (epoch > 0) and (epoch % 10 == 0):\n",
        "                new_learning_rate = self.disc_optimizer.learning_rate / 10.0\n",
        "                print(\" * Update learning rate of discriminator model to: \", new_learning_rate)\n",
        "                print(\" * Update learning rate of the whole model to: \", new_learning_rate)\n",
        "                backend.set_value(self.discriminator_model.optimizer.learning_rate, new_learning_rate)\n",
        "                backend.set_value(self.supervised_discriminator_model.optimizer.learning_rate, new_learning_rate)\n",
        "            \n",
        "            N = max([source_image.shape[0], target_image.shape[0]])\n",
        "            n_steps = N // batch_size\n",
        "            for i in np.arange(n_steps):\n",
        "\n",
        "                idx_source = np.random.randint(0, source_image.shape[0], batch_size)\n",
        "                batch_source_image = source_image[idx_source]\n",
        "                batch_source_label = source_label[idx_source]\n",
        "\n",
        "                idx_target = np.random.randint(0, target_image.shape[0], batch_size)\n",
        "                batch_target_image = target_image[idx_target]\n",
        "\n",
        "                # ----- Preprocess image -----\n",
        "                processed_batch_source_image = []\n",
        "                for image in batch_source_image:\n",
        "                    image = normPro.preprocess(image)\n",
        "                    processed_batch_source_image.append(image)\n",
        "                batch_source_image = np.array(processed_batch_source_image)\n",
        "\n",
        "                processed_batch_target_image = []\n",
        "                for image in batch_target_image:\n",
        "                    image = normPro.preprocess(image)\n",
        "                    processed_batch_target_image.append(image)\n",
        "                    \n",
        "                batch_target_image = np.array(processed_batch_target_image)\n",
        "\n",
        "                # ----- Prepare data -----\n",
        "                source_encode = self.source_encoder.predict(batch_source_image)\n",
        "                target_encode = self.target_encoder.predict(batch_target_image)\n",
        "                encode = np.concatenate((source_encode, target_encode))\n",
        "                \n",
        "                encode_label = ([0.9] * batch_source_image.shape[0]) + ([0.1] * batch_target_image.shape[0])  # soft label: source: 0.9, target: 0.1\n",
        "                encode_label = np.reshape(encode_label, (-1,))\n",
        "                (encode, encode_label) = shuffle(encode, encode_label)\n",
        "\n",
        "                # ----- Train supervised discriminator -----\n",
        "                classificationLloss = self.supervised_discriminator_model.train_on_batch(source_encode, batch_source_label)\n",
        "\n",
        "                # ----- Train unsupervised discriminator -----\n",
        "                discLoss = self.discriminator_model.train_on_batch(encode, encode_label)\n",
        "\n",
        "                # ----- Train target encoder -----\n",
        "                fakeLabels = [1.0] * batch_target_image.shape[0]\n",
        "                fakeLabels = np.reshape(fakeLabels, (-1,))\n",
        "                (batch_target_image, fakeLabels) = shuffle(batch_target_image, fakeLabels)\n",
        "\n",
        "                # ----- Adversarial training with interted label -----\n",
        "                adversarialLoss = whole_target_disc_model.train_on_batch(batch_target_image, fakeLabels)\n",
        "\n",
        "            print(\"Classification loss: {}, discriminator loss: {}, adversarial loss: {}\".format(classificationLloss, discLoss, adversarialLoss))\n",
        "\n",
        "        self.target_encoder.save(os.path.join(\"model\", \"target_encoder.h5\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et3bHPGouyW_"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td3zQAXum_Ll",
        "outputId": "7d889783-305a-4d91-d1c0-26ccdacbac2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Classifier\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " global_average_pooling2d (G  (None, 256)              0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               25700     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 505       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,205\n",
            "Trainable params: 26,205\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- INFOR OF DATASET ----------\n",
            "Name: labelme\n",
            "---- X train shape: (20000, 64, 64, 3)\n",
            "---- y train shape: (20000, 5)\n",
            "---- X validation shape: (2500, 64, 64, 3)\n",
            "---- y validation shape: (2500, 5)\n",
            "---- X test shape: (2500, 64, 64, 3)\n",
            "---- y test shape: (2500, 5)\n",
            "Model: \"encoder_classifier\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        1568      \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 64)        32832     \n",
            "                                                                 \n",
            " re_lu_1 (ReLU)              (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 128)         131200    \n",
            "                                                                 \n",
            " re_lu_2 (ReLU)              (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 256)         524544    \n",
            "                                                                 \n",
            " re_lu_3 (ReLU)              (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " Classifier (Sequential)     (None, 5)                 26205     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 716,349\n",
            "Trainable params: 716,349\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "312/312 [==============================] - 7s 12ms/step - loss: 1.4391 - accuracy: 0.3488 - val_loss: 1.2488 - val_accuracy: 0.4431\n",
            "Epoch 2/30\n",
            "312/312 [==============================] - 3s 10ms/step - loss: 1.0878 - accuracy: 0.5453 - val_loss: 0.8574 - val_accuracy: 0.6635\n",
            "Epoch 3/30\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.7384 - accuracy: 0.7054 - val_loss: 0.6197 - val_accuracy: 0.7540\n",
            "Epoch 4/30\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.5376 - accuracy: 0.7817 - val_loss: 0.5013 - val_accuracy: 0.7889\n",
            "Epoch 5/30\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.4245 - accuracy: 0.8262 - val_loss: 0.5338 - val_accuracy: 0.7969\n",
            "Epoch 6/30\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.3521 - accuracy: 0.8561 - val_loss: 0.4585 - val_accuracy: 0.8297\n",
            "Epoch 7/30\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.3024 - accuracy: 0.8766 - val_loss: 0.4768 - val_accuracy: 0.8221\n",
            "Epoch 8/30\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.2388 - accuracy: 0.9031 - val_loss: 0.4763 - val_accuracy: 0.8365\n",
            "Epoch 9/30\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.2034 - accuracy: 0.9200 - val_loss: 0.4322 - val_accuracy: 0.8594\n",
            "Epoch 10/30\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.1508 - accuracy: 0.9429 - val_loss: 0.4709 - val_accuracy: 0.8458\n",
            "Epoch 11/30\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.1172 - accuracy: 0.9584 - val_loss: 0.4571 - val_accuracy: 0.8650\n",
            "Epoch 12/30\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.0937 - accuracy: 0.9675 - val_loss: 0.5859 - val_accuracy: 0.8522\n",
            "Epoch 13/30\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.0836 - accuracy: 0.9717 - val_loss: 0.4982 - val_accuracy: 0.8598\n",
            "Epoch 14/30\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.0662 - accuracy: 0.9775 - val_loss: 0.5987 - val_accuracy: 0.8654\n",
            "Epoch 15/30\n",
            "312/312 [==============================] - 3s 8ms/step - loss: 0.0530 - accuracy: 0.9820 - val_loss: 0.5684 - val_accuracy: 0.8762\n",
            "Epoch 16/30\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.0483 - accuracy: 0.9837 - val_loss: 0.5549 - val_accuracy: 0.8710\n",
            "Epoch 17/30\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.0487 - accuracy: 0.9839 - val_loss: 0.4628 - val_accuracy: 0.8854\n",
            "Epoch 18/30\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.0438 - accuracy: 0.9863 - val_loss: 0.5701 - val_accuracy: 0.8834\n",
            "Epoch 19/30\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.0311 - accuracy: 0.9898 - val_loss: 0.5736 - val_accuracy: 0.8838\n",
            "Epoch 20/30\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.0450 - accuracy: 0.9854 - val_loss: 0.5929 - val_accuracy: 0.8770\n",
            "Epoch 21/30\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.0393 - accuracy: 0.9881 - val_loss: 0.6633 - val_accuracy: 0.8758\n",
            "Epoch 22/30\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.0323 - accuracy: 0.9900 - val_loss: 0.6393 - val_accuracy: 0.8830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---CLASSIFICATION REPORT ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.95      0.96       497\n",
            "           1       0.79      0.78      0.78       525\n",
            "           2       0.93      0.94      0.93       481\n",
            "           3       0.96      0.95      0.96       507\n",
            "           4       0.71      0.74      0.73       490\n",
            "\n",
            "    accuracy                           0.87      2500\n",
            "   macro avg       0.87      0.87      0.87      2500\n",
            "weighted avg       0.87      0.87      0.87      2500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Training base model\n",
        "\n",
        "adda = ADDA()\n",
        "\n",
        "adda.define_source_encoder()\n",
        "\n",
        "adda.define_classifier()\n",
        "\n",
        "model = adda.get_encoder_and_classifier()\n",
        "\n",
        "adda.train_source_model(model, epochs=TRAIN_SOURCE_EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIfxIX8bmETk",
        "outputId": "5fb9a349-ac83-435f-9603-338effd9cd7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- INFOR OF DATASET ----------\n",
            "Name: caltech\n",
            "---- X train shape: (20000, 64, 64, 3)\n",
            "---- y train shape: (20000, 5)\n",
            "---- X validation shape: (2500, 64, 64, 3)\n",
            "---- y validation shape: (2500, 5)\n",
            "---- X test shape: (2500, 64, 64, 3)\n",
            "---- y test shape: (2500, 5)\n"
          ]
        }
      ],
      "source": [
        "# Load target dataset\n",
        "\n",
        "((X_train_target, y_train_target), (X_validation_target, y_validation_target), (_, _)) = get_dataset(tgt_dataset)\n",
        "\n",
        "target_x = np.concatenate((X_train_target, X_validation_target), axis=0)\n",
        "target_y = np.concatenate((y_train_target, y_validation_target), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpCvG-3I05V_",
        "outputId": "a1dfa397-0642-4378-f274-dfe0daf2dc76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is 0.31751111111111113\n"
          ]
        }
      ],
      "source": [
        "model = load_model(\"/content/model/source_classification.h5\")\n",
        "\n",
        "# Preprocess\n",
        "normPro = NomalizePreprocessor()\n",
        "\n",
        "# Predict\n",
        "testGen = PredictGenerator(target_x, batchSize=BATCH_SIZE, preprocessors = [normPro])\n",
        "\n",
        "predict_labels = model.predict(testGen)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = np.sum(predict_labels.argmax(-1) == target_y.argmax(-1)) / len(target_y)\n",
        "\n",
        "print(\"Accuracy is {}\".format(accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8lfKNCy3ItW",
        "outputId": "85aaedfc-4e5e-43e2-91f4-b239df7513d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- INFOR OF DATASET ----------\n",
            "Name: labelme\n",
            "---- X train shape: (20000, 64, 64, 3)\n",
            "---- y train shape: (20000, 5)\n",
            "---- X validation shape: (2500, 64, 64, 3)\n",
            "---- y validation shape: (2500, 5)\n",
            "---- X test shape: (2500, 64, 64, 3)\n",
            "---- y test shape: (2500, 5)\n",
            "---------- INFOR OF DATASET ----------\n",
            "Name: caltech\n",
            "---- X train shape: (20000, 64, 64, 3)\n",
            "---- y train shape: (20000, 5)\n",
            "---- X validation shape: (2500, 64, 64, 3)\n",
            "---- y validation shape: (2500, 5)\n",
            "---- X test shape: (2500, 64, 64, 3)\n",
            "---- y test shape: (2500, 5)\n",
            "[INFO]: target_encoder is copy from model/source_encoder.h5\n",
            "Model: \"supervised_discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 4, 4, 256)]       0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 8, 8, 128)        524416    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 16, 16, 64)       131136    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 32, 32, 32)       32800     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 64, 64, 3)        1539      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 64, 64, 3)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12288)             0         \n",
            "                                                                 \n",
            " discriminator3 (Dense)      (None, 5)                 61445     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 751,336\n",
            "Trainable params: 751,336\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"unsupervised_discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 4, 4, 256)]       0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 8, 8, 128)        524416    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 16, 16, 64)       131136    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 32, 32, 32)       32800     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 64, 64, 3)        1539      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 64, 64, 3)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12288)             0         \n",
            "                                                                 \n",
            " discriminator3 (Dense)      (None, 5)                 61445     \n",
            "                                                                 \n",
            " lambda (Lambda)             (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 751,336\n",
            "Trainable params: 751,336\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        1568      \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 64)        32832     \n",
            "                                                                 \n",
            " re_lu_1 (ReLU)              (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 128)         131200    \n",
            "                                                                 \n",
            " re_lu_2 (ReLU)              (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 256)         524544    \n",
            "                                                                 \n",
            " re_lu_3 (ReLU)              (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " unsupervised_discriminator   (None, 1)                751336    \n",
            " (Functional)                                                    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,441,480\n",
            "Trainable params: 690,144\n",
            "Non-trainable params: 751,336\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----[INFO] starting epoch 0 of 20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Accuracy at epoch 0: is 0.31751111111111113\n",
            "Classification loss: [0.05339164286851883, 1.0], discriminator loss: 0.5326501131057739, adversarial loss: 1.1928521394729614\n",
            "-----[INFO] starting epoch 1 of 20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification loss: [0.016814637929201126, 1.0], discriminator loss: 0.4815428555011749, adversarial loss: 1.4615404605865479\n",
            "-----[INFO] starting epoch 2 of 20...\n",
            " * Accuracy at epoch 2: is 0.4212888888888889\n",
            "Classification loss: [0.03607308864593506, 0.984375], discriminator loss: 0.4545063078403473, adversarial loss: 1.875016689300537\n",
            "-----[INFO] starting epoch 3 of 20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification loss: [0.026041947305202484, 1.0], discriminator loss: 0.45777490735054016, adversarial loss: 1.5607380867004395\n",
            "-----[INFO] starting epoch 4 of 20...\n",
            " * Accuracy at epoch 4: is 0.4126666666666667\n",
            "Classification loss: [0.0627671480178833, 0.984375], discriminator loss: 0.43504977226257324, adversarial loss: 2.14914870262146\n",
            "-----[INFO] starting epoch 5 of 20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification loss: [0.015612173825502396, 1.0], discriminator loss: 0.3942447900772095, adversarial loss: 2.0636379718780518\n",
            "-----[INFO] starting epoch 6 of 20...\n",
            " * Accuracy at epoch 6: is 0.41346666666666665\n",
            "Classification loss: [0.00872910674661398, 1.0], discriminator loss: 0.37695181369781494, adversarial loss: 2.3064842224121094\n",
            "-----[INFO] starting epoch 7 of 20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification loss: [0.005006415769457817, 1.0], discriminator loss: 0.39206674695014954, adversarial loss: 2.0003461837768555\n",
            "-----[INFO] starting epoch 8 of 20...\n",
            " * Accuracy at epoch 8: is 0.4265333333333333\n",
            "Classification loss: [0.003885036800056696, 1.0], discriminator loss: 0.36920255422592163, adversarial loss: 2.370940685272217\n",
            "-----[INFO] starting epoch 9 of 20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification loss: [0.002482770709320903, 1.0], discriminator loss: 0.36744141578674316, adversarial loss: 2.615706443786621\n",
            "-----[INFO] starting epoch 10 of 20...\n",
            " * Accuracy at epoch 10: is 0.4002222222222222\n",
            " * Update learning rate of discriminator model to:  tf.Tensor(2e-05, shape=(), dtype=float32)\n",
            " * Update learning rate of the whole model to:  tf.Tensor(2e-05, shape=(), dtype=float32)\n",
            "Classification loss: [0.0026985076256096363, 1.0], discriminator loss: 0.35662364959716797, adversarial loss: 2.2550392150878906\n",
            "-----[INFO] starting epoch 11 of 20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification loss: [0.0021507302299141884, 1.0], discriminator loss: 0.3458896577358246, adversarial loss: 2.2862608432769775\n",
            "-----[INFO] starting epoch 12 of 20...\n",
            " * Accuracy at epoch 12: is 0.41075555555555554\n",
            "Classification loss: [0.0017684760969132185, 1.0], discriminator loss: 0.3416332006454468, adversarial loss: 2.3390700817108154\n",
            "-----[INFO] starting epoch 13 of 20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification loss: [0.00077054463326931, 1.0], discriminator loss: 0.3414863348007202, adversarial loss: 2.403653621673584\n",
            "-----[INFO] starting epoch 14 of 20...\n",
            " * Accuracy at epoch 14: is 0.4166666666666667\n",
            "Classification loss: [0.0007943145465105772, 1.0], discriminator loss: 0.33924585580825806, adversarial loss: 2.4550833702087402\n",
            "-----[INFO] starting epoch 15 of 20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification loss: [0.0009978319285437465, 1.0], discriminator loss: 0.33601075410842896, adversarial loss: 2.283836841583252\n",
            "-----[INFO] starting epoch 16 of 20...\n",
            " * Accuracy at epoch 16: is 0.4202666666666667\n",
            "Classification loss: [0.0007056323811411858, 1.0], discriminator loss: 0.33496326208114624, adversarial loss: 2.2531862258911133\n",
            "-----[INFO] starting epoch 17 of 20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification loss: [0.000953222974203527, 1.0], discriminator loss: 0.3360322117805481, adversarial loss: 2.298093557357788\n",
            "-----[INFO] starting epoch 18 of 20...\n",
            " * Accuracy at epoch 18: is 0.42004444444444444\n",
            "Classification loss: [0.0005283233476802707, 1.0], discriminator loss: 0.3338906168937683, adversarial loss: 2.3598904609680176\n",
            "-----[INFO] starting epoch 19 of 20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification loss: [0.0007404007483273745, 1.0], discriminator loss: 0.3356924057006836, adversarial loss: 2.281806707382202\n"
          ]
        }
      ],
      "source": [
        "# Training adversarial network\n",
        "\n",
        "adda.define_discriminator(adda.source_encoder.output_shape[1:])\n",
        "adda.train_target(epochs=ADVERSARIAL_EPOCHS, test_images=target_x, test_labels=target_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-d-dHOkX0Rjq"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict on the train and validation dataset"
      ],
      "metadata": {
        "id": "Qe0zQY5cHmSG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLYMThc9p6qJ",
        "outputId": "dc8d5e10-ac79-4e36-9070-362a59978d9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is 0.4198222222222222\n"
          ]
        }
      ],
      "source": [
        "# Predict on the train and validation dataset\n",
        "\n",
        "encoder_model = load_model(\"/content/model/target_encoder.h5\")\n",
        "\n",
        "classifier_model = load_model(\"/content/model/classifier.h5\")\n",
        "\n",
        "predict_labels = Predict_Encoder_Classifier(encoder_model, classifier_model, target_x, batchSize=BATCH_SIZE, preprocessors = [normPro])\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = np.sum(predict_labels.argmax(-1) == target_y.argmax(-1)) / len(target_y)\n",
        "\n",
        "print(\"Accuracy is {}\".format(accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predit on the testing dataset"
      ],
      "metadata": {
        "id": "HicdPzO9TYgG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJlPEiTG8jrr",
        "outputId": "a20e0dc3-34a9-48a3-cdd1-7c7dc5602cdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- INFOR OF DATASET ----------\n",
            "Name: caltech\n",
            "---- X train shape: (20000, 64, 64, 3)\n",
            "---- y train shape: (20000, 5)\n",
            "---- X validation shape: (2500, 64, 64, 3)\n",
            "---- y validation shape: (2500, 5)\n",
            "---- X test shape: (2500, 64, 64, 3)\n",
            "---- y test shape: (2500, 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is 0.41\n"
          ]
        }
      ],
      "source": [
        "# Load target dataset\n",
        "((_, _), (_, _), (X_testing_target, y_testing_target)) = get_dataset(tgt_dataset)\n",
        "\n",
        "# Predict\n",
        "encoder_model = load_model(\"/content/model/target_encoder.h5\")\n",
        "classifier_model = load_model(\"/content/model/classifier.h5\")\n",
        "\n",
        "predict_labels = Predict_Encoder_Classifier(encoder_model, classifier_model, X_testing_target, batchSize=BATCH_SIZE, preprocessors = [normPro])\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = np.sum(predict_labels.argmax(-1) == y_testing_target.argmax(-1)) / len(y_testing_target)\n",
        "print(\"Accuracy is {}\".format(accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sPflYB1kUKPf"
      },
      "execution_count": 19,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}